{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'home_win'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 187\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Call the main function\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 187\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 158\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    155\u001B[0m df_fixtures \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/results201718.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    157\u001B[0m \u001B[38;5;66;03m# Predict the outcomes of fixtures\u001B[39;00m\n\u001B[0;32m--> 158\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mpredict_outcomes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_fixtures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mratings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# Compare the predictions with the actual results\u001B[39;00m\n\u001B[1;32m    161\u001B[0m correct_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "Cell \u001B[0;32mIn[1], line 132\u001B[0m, in \u001B[0;36mpredict_outcomes\u001B[0;34m(df_fixtures, ratings)\u001B[0m\n\u001B[1;32m    129\u001B[0m probabilities \u001B[38;5;241m=\u001B[39m ratings[home_team]\n\u001B[1;32m    131\u001B[0m \u001B[38;5;66;03m# Make a prediction based on the highest probability\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mprobabilities\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhome_win\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m>\u001B[39m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdraw\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhome_win\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maway_win\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m    133\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHome Win\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdraw\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhome_win\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdraw\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m probabilities[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maway_win\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'home_win'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to initialize ratings\n",
    "def initialize_ratings(df_results):\n",
    "    ratings = {}\n",
    "\n",
    "    # Iterate over teams in the results data\n",
    "    teams = set(df_results['home_team']).union(set(df_results['away_team']))\n",
    "    for team in teams:\n",
    "        # Initialize ratings for home and away\n",
    "        ratings[team] = {\n",
    "            'brH': 0.0,\n",
    "            'brA': 0.0,\n",
    "            'prH': 0.0,\n",
    "            'prA': 0.0,\n",
    "            'continuous_underperformances': 0,\n",
    "            'continuous_overperformances': 0\n",
    "        }\n",
    "\n",
    "    return ratings\n",
    "\n",
    "# Function to update ratings based on results data\n",
    "def update_ratings(df_results, ratings):\n",
    "    learning_rate_lambda = 0.054\n",
    "    diminishing_factor_phi = 3\n",
    "    learning_rate_gamma = 0.79\n",
    "    form_threshold_phi = 1\n",
    "    rating_impact_mu = 0.01\n",
    "    diminishing_factor_delta = 2.5\n",
    "\n",
    "    # Iterate over each match in the results data\n",
    "    for index, row in df_results.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        observed_goal_difference = row['home_goals'] - row['away_goals']\n",
    "\n",
    "        # Calculate expected goal difference based on ratings\n",
    "        expected_goal_difference = ratings[home_team]['brH'] - ratings[away_team]['brA']\n",
    "\n",
    "        # Calculate the error between observed and expected goal difference\n",
    "        error = abs(observed_goal_difference - expected_goal_difference)\n",
    "\n",
    "        # Update the home team ratings\n",
    "        ratings[home_team]['brH'] += diminishing_factor_phi * np.log10(1 + error) * learning_rate_lambda\n",
    "        ratings[home_team]['brA'] += (ratings[home_team]['brH'] - ratings[home_team]['brA']) * learning_rate_gamma\n",
    "\n",
    "        # Update the away team ratings\n",
    "        ratings[away_team]['brA'] += diminishing_factor_phi * np.log10(1 + error) * learning_rate_lambda\n",
    "        ratings[away_team]['brH'] += (ratings[away_team]['brA'] - ratings[away_team]['brH']) * learning_rate_gamma\n",
    "\n",
    "        # Update the continuous under/over-performance counters\n",
    "        if observed_goal_difference < expected_goal_difference:\n",
    "            ratings[home_team]['continuous_underperformances'] += 1\n",
    "            ratings[away_team]['continuous_overperformances'] += 1\n",
    "        elif observed_goal_difference > expected_goal_difference:\n",
    "            ratings[home_team]['continuous_overperformances'] += 1\n",
    "            ratings[away_team]['continuous_underperformances'] += 1\n",
    "        else:\n",
    "            ratings[home_team]['continuous_underperformances'] = 0\n",
    "            ratings[away_team]['continuous_underperformances'] = 0\n",
    "\n",
    "        # Update the provisional ratings based on form factor\n",
    "        if ratings[home_team]['continuous_underperformances'] > form_threshold_phi:\n",
    "            if form_threshold_phi > 1:\n",
    "                form_impact = rating_impact_mu * (ratings[home_team]['continuous_underperformances'] - form_threshold_phi) / ((form_threshold_phi - 1) * diminishing_factor_delta)\n",
    "            else:\n",
    "                form_impact = rating_impact_mu * (ratings[home_team]['continuous_underperformances'] - form_threshold_phi)\n",
    "            ratings[home_team]['prH'] = ratings[home_team]['brH'] - form_impact\n",
    "        elif ratings[home_team]['continuous_overperformances'] > form_threshold_phi:\n",
    "            if form_threshold_phi > 1:\n",
    "                form_impact = rating_impact_mu * (ratings[home_team]['continuous_overperformances'] - form_threshold_phi) / ((form_threshold_phi - 1) * diminishing_factor_delta)\n",
    "            else:\n",
    "                form_impact = rating_impact_mu * (ratings[home_team]['continuous_overperformances'] - form_threshold_phi)\n",
    "            ratings[home_team]['prH'] = ratings[home_team]['brH'] + form_impact\n",
    "        else:\n",
    "            ratings[home_team]['prH'] = ratings[home_team]['brH']\n",
    "\n",
    "        if ratings[away_team]['continuous_underperformances'] > form_threshold_phi:\n",
    "            if form_threshold_phi > 1:\n",
    "                form_impact = rating_impact_mu * (ratings[away_team]['continuous_underperformances'] - form_threshold_phi) / ((form_threshold_phi - 1) * diminishing_factor_delta)\n",
    "            else:\n",
    "                form_impact = rating_impact_mu * (ratings[away_team]['continuous_underperformances'] - form_threshold_phi)\n",
    "            ratings[away_team]['prA'] = ratings[away_team]['brA'] - form_impact\n",
    "        elif ratings[away_team]['continuous_overperformances'] > form_threshold_phi:\n",
    "            if form_threshold_phi > 1:\n",
    "                form_impact = rating_impact_mu * (ratings[away_team]['continuous_overperformances'] - form_threshold_phi) / ((form_threshold_phi - 1) * diminishing_factor_delta)\n",
    "            else:\n",
    "                form_impact = rating_impact_mu * (ratings[away_team]['continuous_overperformances'] - form_threshold_phi)\n",
    "            ratings[away_team]['prA'] = ratings[away_team]['brA'] + form_impact\n",
    "        else:\n",
    "            ratings[away_team]['prA'] = ratings[away_team]['brA']\n",
    "\n",
    "    return ratings\n",
    "\n",
    "# Function to calculate probabilities based on ratings\n",
    "def calculate_probabilities(ratings):\n",
    "    probabilities = {}\n",
    "\n",
    "    # Iterate over teams and calculate probabilities\n",
    "    for team in ratings:\n",
    "        home_rating = ratings[team]['prH']\n",
    "        away_rating = ratings[team]['prA']\n",
    "\n",
    "        # Calculate probabilities based on ratings\n",
    "        total_rating = home_rating + away_rating\n",
    "        home_win_prob = home_rating / total_rating\n",
    "        draw_prob = 1 / total_rating\n",
    "        away_win_prob = away_rating / total_rating\n",
    "\n",
    "        probabilities[team] = {\n",
    "            'home_win': home_win_prob,\n",
    "            'draw': draw_prob,\n",
    "            'away_win': away_win_prob\n",
    "        }\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "# Function to predict outcomes for fixtures\n",
    "def predict_outcomes(df_fixtures, ratings):\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over each fixture in the fixtures data\n",
    "    for index, row in df_fixtures.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "\n",
    "        # Get the probabilities for home-win, draw, and away-win\n",
    "        probabilities = ratings[home_team]\n",
    "\n",
    "        # Make a prediction based on the highest probability\n",
    "        if probabilities['home_win'] > probabilities['draw'] and probabilities['home_win'] > probabilities['away_win']:\n",
    "            prediction = 'Home Win'\n",
    "        elif probabilities['draw'] > probabilities['home_win'] and probabilities['draw'] > probabilities['away_win']:\n",
    "            prediction = 'Draw'\n",
    "        else:\n",
    "            prediction = 'Away Win'\n",
    "\n",
    "        predictions.append((home_team, away_team, prediction))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load the results data file\n",
    "    df_results = pd.read_csv('../data/results.csv')\n",
    "\n",
    "    # Initialize ratings based on the results data\n",
    "    ratings = initialize_ratings(df_results)\n",
    "\n",
    "    # Update ratings based on the results data\n",
    "    ratings = update_ratings(df_results, ratings)\n",
    "\n",
    "    # Load the fixtures data file for prediction\n",
    "    df_fixtures = pd.read_csv('../data/results201718.csv')\n",
    "\n",
    "    # Predict the outcomes of fixtures\n",
    "    predictions = predict_outcomes(df_fixtures, ratings)\n",
    "\n",
    "    # Compare the predictions with the actual results\n",
    "    correct_predictions = 0\n",
    "    for index, row in df_fixtures.iterrows():\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        actual_result = row['result']\n",
    "\n",
    "        # Find the corresponding prediction for the fixture\n",
    "        prediction = [p for p in predictions if p[0] == home_team and p[1] == away_team][0][2]\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        if actual_result == prediction:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        # Output the prediction\n",
    "        print(f\"{home_team} - {away_team}: Outcome Predictions (Home Win, Draw, Away Win)\")\n",
    "        print(f\"We predict: {prediction}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate the accuracy of the predictions\n",
    "    accuracy = correct_predictions / len(df_fixtures) * 100\n",
    "\n",
    "    # Output the overall accuracy\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "# Call the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T11:38:36.429800Z",
     "start_time": "2023-07-13T11:38:35.231957Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
