{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tqdm\n",
    "from scipy.interpolate import griddata\n",
    "import heapq\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to initialize ratings\n",
    "def initialize_ratings(df_results, df_fixtures, df_int_results, df_int_fixtures):\n",
    "    ratings = {}\n",
    "    league_ratings = {}\n",
    "\n",
    "    # Get the list of competitions\n",
    "    competitions = set(df_results['Div']).union(set(df_fixtures['Div'])).union(set(df_int_results['HomeDiv'])).union(set(df_int_fixtures['HomeDiv'])).union(set(df_int_results['AwayDiv'])).union(set(df_int_fixtures['AwayDiv']))\n",
    "\n",
    "    # Iterate over teams in the results data\n",
    "    teams = set(df_results['HomeTeam']).union(set(df_results['AwayTeam'])).union(set(df_fixtures['HomeTeam'])).union(set(df_fixtures['AwayTeam'])).union(set(df_int_results['HomeTeam'])).union(set(df_int_fixtures['HomeTeam'])).union(set(df_int_results['AwayTeam'])).union(set(df_int_fixtures['AwayTeam']))\n",
    "\n",
    "    for team in teams:\n",
    "        ratings[team] = {}\n",
    "\n",
    "        # Initialize ratings for each team for each competition\n",
    "        for competition in competitions:\n",
    "            ratings[team][competition] = {\n",
    "                'brH': 0.0,\n",
    "                'brA': 0.0,\n",
    "                'continuous_overunderperformances': 0\n",
    "            }\n",
    "            \n",
    "    \"\"\"\n",
    "    # Initialize ratings for each competition\n",
    "    league_ratings['REST'] = {\n",
    "        'brH': 0.0,\n",
    "        'brA': 0.0,\n",
    "        'continuous_overunderperformances': 0\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    for competition in competitions:\n",
    "        league_ratings[competition] = {\n",
    "            'brH': 0.0,\n",
    "            'brA': 0.0,\n",
    "            'continuous_overunderperformances': 0\n",
    "        }\n",
    "\n",
    "    #print('Teams:', teams, end='\\n\\n')\n",
    "    return ratings, league_ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initialize_rest_ratings(rest_teams):\n",
    "    rest_ratings = {}\n",
    "    for team in rest_teams:\n",
    "        rest_ratings[team] = {\n",
    "            'REST': {\n",
    "                'brH': 0.0,\n",
    "                'brA': 0.0,\n",
    "                'continuous_overunderperformances': 0\n",
    "            }\n",
    "        }\n",
    "    return rest_ratings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_team_to_league_mapping(df_results, df_fixtures, df_int):\n",
    "    team_to_league = {}\n",
    "    rest_teams = set() # To store teams that are assigned to the 'REST' league\n",
    "\n",
    "    def get_league_level(division):\n",
    "        # Extracting the integer part from the division\n",
    "        integer_part = ''.join(filter(str.isdigit, division))\n",
    "        return int(integer_part)\n",
    "\n",
    "\n",
    "    # Iterate through the results and fixtures dataframes and map teams to their leagues\n",
    "    for df in [df_results, df_fixtures]:\n",
    "        for index, row in df.iterrows():\n",
    "            for team in [row['HomeTeam'], row['AwayTeam']]:\n",
    "                current_div = row['Div']\n",
    "                current_level = get_league_level(current_div)\n",
    "\n",
    "                # If the team is not yet in the dictionary, or if the current league is higher, update the entry\n",
    "                if team not in team_to_league or current_level < get_league_level(team_to_league[team]):\n",
    "                    team_to_league[team] = current_div\n",
    "\n",
    "    # Now process df_int\n",
    "    for index, row in df_int.iterrows():\n",
    "        for team in [row['HomeTeam'], row['AwayTeam']]:\n",
    "            if team not in team_to_league:\n",
    "                # If the team is not found in the other dataframes, assign it to 'REST'\n",
    "                team_to_league[team] = 'REST'\n",
    "                rest_teams.add(team)\n",
    "\n",
    "    return team_to_league, rest_teams"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_league_from_team(team, team_to_league):\n",
    "    return team_to_league.get(team, 'REST')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to update ratings based on results data\n",
    "def update_ratings_multiple_games(df_results, ratings, rates):\n",
    "    ind_threshold = rates['ind_threshold']\n",
    "    games_with_rating = []\n",
    "    training_games = []\n",
    "\n",
    "    # Iterate over each match in the results data\n",
    "    for index, row in df_results.iterrows():\n",
    "\n",
    "        # Identify the competition in which the match took place\n",
    "        competition = row['Div']\n",
    "\n",
    "        if index > ind_threshold:\n",
    "            #add current game to training data\n",
    "            training_games.append({\n",
    "                \"brH_x\": ratings[row[\"HomeTeam\"]][competition][\"brH\"],\n",
    "                \"brA_x\": ratings[row[\"HomeTeam\"]][competition][\"brA\"],\n",
    "                \"prH_x\": calculate_provisional_ratings(ratings, row[\"HomeTeam\"], competition, rates)[0],\n",
    "                \"prA_x\": calculate_provisional_ratings(ratings, row[\"HomeTeam\"], competition, rates)[1],\n",
    "                \"brH_y\": ratings[row[\"AwayTeam\"]][competition][\"brH\"],\n",
    "                \"brA_y\": ratings[row[\"AwayTeam\"]][competition][\"brA\"],\n",
    "                \"prH_y\": calculate_provisional_ratings(ratings, row[\"AwayTeam\"], competition, rates)[0],\n",
    "                \"prA_y\": calculate_provisional_ratings(ratings, row[\"AwayTeam\"], competition, rates)[1],\n",
    "                \"rating_difference\": (calculate_provisional_ratings(ratings, row[\"HomeTeam\"], competition, rates)[0]) - (calculate_provisional_ratings(ratings, row[\"AwayTeam\"], competition, rates)[1]),\n",
    "                \"FTHG\": row[\"FTHG\"],\n",
    "                \"FTAG\": row[\"FTAG\"],\n",
    "                \"FTR\": row[\"FTR\"]\n",
    "            })\n",
    "\n",
    "\n",
    "        if np.isnan(ratings[row[\"HomeTeam\"]][competition][\"brH\"]):\n",
    "            print(\"error\")\n",
    "            break\n",
    "\n",
    "        ratings = update_ratings_single_game(row['HomeTeam'], row['AwayTeam'], row['FTHG'], row['FTAG'], ratings, rates, competition)\n",
    "\n",
    "        games_with_rating.append({\n",
    "            \"team\": row[\"HomeTeam\"],\n",
    "            \"home_rating\": ratings[row[\"HomeTeam\"]][competition][\"brH\"],\n",
    "            \"away_rating\": ratings[row[\"HomeTeam\"]][competition][\"brA\"],\n",
    "            \"continuous_overunderperformances\": ratings[row[\"HomeTeam\"]][competition][\"continuous_overunderperformances\"],\n",
    "        })\n",
    "\n",
    "        games_with_rating.append({\n",
    "            \"team\": row[\"AwayTeam\"],\n",
    "            \"home_rating\": ratings[row[\"AwayTeam\"]][competition][\"brH\"],\n",
    "            \"away_rating\": ratings[row[\"AwayTeam\"]][competition][\"brA\"],\n",
    "            \"continuous_overunderperformances\": ratings[row[\"AwayTeam\"]][competition][\"continuous_overunderperformances\"],\n",
    "        })\n",
    "\n",
    "    return ratings, games_with_rating, training_games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_league_ratings_multiple_games(df_int_results, league_ratings, rates):\n",
    "    # Iterate over each match in the international results data\n",
    "    for index, row in df_int_results.iterrows():\n",
    "        # Extract relevant information from the row\n",
    "        HomeLeague = row['HomeDiv']\n",
    "        AwayLeague = row['AwayDiv']\n",
    "        FTHG = row['FTHG']\n",
    "        FTAG = row['FTAG']\n",
    "\n",
    "        # Update the league ratings based on the match result\n",
    "        league_ratings = update_league_ratings_single_game(HomeLeague, AwayLeague, FTHG, FTAG, league_ratings, rates)\n",
    "\n",
    "    return league_ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to update ratings based on results data\n",
    "def update_ratings_single_game(HomeTeam, AwayTeam, FTHG, FTAG, ratings, rates, competition):\n",
    "\n",
    "    #lambda: Determines to what extent the new match results influence the team ratings (could be improved to include temporal difference between matches)\n",
    "    #learning_rate_lambda = 0.054\n",
    "    learning_rate_lambda = rates['lambda']\n",
    "\n",
    "    #psi: diminish the impact each additional goal difference error has on team ratings\n",
    "    diminishing_function_psi = lambda error: 3 * np.log10(1 + error)\n",
    "\n",
    "    #gamma: determines to what extent performances at the home grounds influence away team ratings and vice versa\n",
    "    #learning_rate_gamma = 0.79\n",
    "    learning_rate_gamma = rates['gamma']\n",
    "    \n",
    "    x = rates['x']\n",
    "    y = rates['y']\n",
    "    a = rates['a']\n",
    "    b = rates['b']\n",
    "\n",
    "    #print(HomeTeam, \"-\", AwayTeam, FTHG, \":\", FTAG)\n",
    "\n",
    "    observed_goal_difference = FTHG - FTAG\n",
    "    #print(\"Observed Goal Difference:\", observed_goal_difference)\n",
    "    \n",
    "    competitions = set(ratings[HomeTeam].keys()).union(set(ratings[AwayTeam].keys()))\n",
    "    \n",
    "    if ratings[HomeTeam][competition]['brH'] == 0 and ratings[HomeTeam][competition]['brA'] == 0:\n",
    "        for otherCompetition in competitions:\n",
    "            if ratings[HomeTeam][otherCompetition]['brH'] != 0 or ratings[HomeTeam][otherCompetition]['brA'] != 0:\n",
    "                if int(''.join(filter(str.isdigit, otherCompetition))) > int(''.join(filter(str.isdigit, competition))):\n",
    "                    ratings[HomeTeam][competition]['brH'] = ratings[HomeTeam][otherCompetition]['brH'] * x + a\n",
    "                    ratings[HomeTeam][competition]['brA'] = ratings[HomeTeam][otherCompetition]['brA'] * x + a\n",
    "                    #print (\"HomeTeam\", HomeTeam, \"competition\", competition, \"otherCompetition\", otherCompetition, \"brH\", ratings[HomeTeam][competition]['brH'], \"brA\", ratings[HomeTeam][competition]['brA'])\n",
    "        \n",
    "                else:\n",
    "                    ratings[HomeTeam][competition]['brH'] = ratings[HomeTeam][otherCompetition]['brH'] * y + b\n",
    "                    ratings[HomeTeam][competition]['brA'] = ratings[HomeTeam][otherCompetition]['brA'] * y + b\n",
    "                    #print (\"HomeTeam\", HomeTeam, \"competition\", competition, \"otherCompetition\", otherCompetition, \"brH\", ratings[HomeTeam][competition]['brH'], \"brA\", ratings[HomeTeam][competition]['brA'])\n",
    "\n",
    "    if ratings[AwayTeam][competition]['brA'] == 0 and ratings[AwayTeam][competition]['brH'] == 0:\n",
    "        for otherCompetition in competitions:\n",
    "            if ratings[AwayTeam][otherCompetition]['brA'] != 0 or ratings[AwayTeam][otherCompetition]['brH'] != 0:\n",
    "                if int(''.join(filter(str.isdigit, otherCompetition))) > int(''.join(filter(str.isdigit, competition))):\n",
    "                    ratings[AwayTeam][competition]['brA'] = ratings[AwayTeam][otherCompetition]['brA'] * x + a\n",
    "                    ratings[AwayTeam][competition]['brH'] = ratings[AwayTeam][otherCompetition]['brH'] * x + a\n",
    "                    #print (\"AwayTeam\", AwayTeam, \"competition\", competition, \"otherCompetition\", otherCompetition, \"brA\", ratings[AwayTeam][competition]['brA'], \"brH\", ratings[AwayTeam][competition]['brH'])\n",
    "                \n",
    "                else:\n",
    "                    ratings[AwayTeam][competition]['brA'] = ratings[AwayTeam][otherCompetition]['brA'] * y + b\n",
    "                    ratings[AwayTeam][competition]['brH'] = ratings[AwayTeam][otherCompetition]['brH'] * y + b\n",
    "                    #print (\"AwayTeam\", AwayTeam, \"competition\", competition, \"otherCompetition\", otherCompetition, \"brA\", ratings[AwayTeam][competition]['brA'], \"brH\", ratings[AwayTeam][competition]['brH'])\n",
    "        \n",
    "\n",
    "    #Calculate expected goals for home team\n",
    "    #expected_goal_x = round((10 ** (abs(ratings[HomeTeam]['brH']) / 3)) - 1,5)\n",
    "    expected_goal_x_temp = abs(ratings[HomeTeam][competition]['brH']) / 3\n",
    "    expected_goal_x = np.sign(ratings[HomeTeam][competition]['brH']) * (np.power(10, expected_goal_x_temp) - 1)\n",
    "    #print(\"Expected Goals x:\", expected_goal_x)\n",
    "\n",
    "    # Calculate expected goals for away team\n",
    "    #expected_goal_y = round((10 ** (abs(ratings[AwayTeam]['brA']) / 3)) - 1,5)\n",
    "    expected_goal_y_temp = abs(ratings[AwayTeam][competition]['brA']) / 3\n",
    "    expected_goal_y = np.sign(ratings[AwayTeam][competition]['brA']) * (np.power(10, expected_goal_y_temp) - 1)\n",
    "    #print(\"Expected Goals y:\", expected_goal_y)\n",
    "\n",
    "    # Calculate expected goal difference based on ratings\n",
    "    expected_goal_difference = expected_goal_x - expected_goal_y\n",
    "    #print(\"Expected Goal Difference:\", expected_goal_difference)\n",
    "\n",
    "    # Calculate the error between observed and expected goal difference\n",
    "    error = abs(observed_goal_difference - expected_goal_difference)\n",
    "    #print(\"error:\", error)\n",
    "\n",
    "    psi_temp = diminishing_function_psi(error)\n",
    "\n",
    "    # Diminish the impact of the goal difference error for both teams x and y respectively\n",
    "    if (expected_goal_difference < observed_goal_difference):\n",
    "        diminishing_function_psi_x = psi_temp\n",
    "        diminishing_function_psi_y = -psi_temp\n",
    "    else:\n",
    "        diminishing_function_psi_x = -psi_temp\n",
    "        diminishing_function_psi_y = psi_temp\n",
    "    #print(\"Diminishing Function psi x:\", diminishing_function_psi_x)\n",
    "    #print(\"Diminishing Function psi y:\", diminishing_function_psi_y)\n",
    "\n",
    "    # Update the home team x background ratings\n",
    "    previous_home_rating_x = ratings[HomeTeam][competition]['brH']\n",
    "    previous_away_rating_x = ratings[HomeTeam][competition]['brA']\n",
    "    #print(\"Old brH x:\", previous_home_rating_x)\n",
    "    #print(\"Old brA x:\", previous_away_rating_x)\n",
    "\n",
    "    ratings[HomeTeam][competition]['brH'] = previous_home_rating_x + diminishing_function_psi_x * learning_rate_lambda\n",
    "    ratings[HomeTeam][competition]['brA'] = previous_away_rating_x + (ratings[HomeTeam][competition]['brH'] - previous_home_rating_x) * learning_rate_gamma\n",
    "    #print(\"New brH x:\", ratings[HomeTeam]['brH'])\n",
    "    #print(\"New brA x:\", ratings[HomeTeam]['brA'])\n",
    "\n",
    "    # Update the away team y background ratings\n",
    "    previous_home_rating_y = ratings[AwayTeam][competition]['brH']\n",
    "    previous_away_rating_y = ratings[AwayTeam][competition]['brA']\n",
    "    #print(\"Old brH y:\", previous_home_rating_y)\n",
    "    #print(\"Old brA y:\", previous_away_rating_y)\n",
    "\n",
    "    ratings[AwayTeam][competition]['brA'] = previous_away_rating_y + diminishing_function_psi_y * learning_rate_lambda\n",
    "    ratings[AwayTeam][competition]['brH'] = previous_home_rating_y + (ratings[AwayTeam][competition]['brA'] - previous_away_rating_y) * learning_rate_gamma\n",
    "    #print(\"New brH y:\", ratings[AwayTeam]['brH'])\n",
    "    #print(\"New brA y:\", ratings[AwayTeam]['brA'])\n",
    "\n",
    "    #print(\"Old overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"Old overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'])\n",
    "\n",
    "    # Update the continuous over/underperformances for the home team\n",
    "    if (observed_goal_difference > expected_goal_difference):\n",
    "        ratings[HomeTeam][competition]['continuous_overunderperformances'] = max(1, ratings[HomeTeam][competition]['continuous_overunderperformances'] + 1)\n",
    "        ratings[AwayTeam][competition]['continuous_overunderperformances'] = min(-1, ratings[AwayTeam][competition]['continuous_overunderperformances'] - 1)\n",
    "    elif (observed_goal_difference < expected_goal_difference):\n",
    "        ratings[HomeTeam][competition]['continuous_overunderperformances'] = min(-1, ratings[HomeTeam][competition]['continuous_overunderperformances'] - 1)\n",
    "        ratings[AwayTeam][competition]['continuous_overunderperformances'] = max(1, ratings[AwayTeam][competition]['continuous_overunderperformances'] + 1)\n",
    "    else:\n",
    "        ratings[HomeTeam][competition]['continuous_overunderperformances'] = 0\n",
    "        ratings[AwayTeam][competition]['continuous_overunderperformances'] = 0\n",
    "\n",
    "    #print(\"New overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"New overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'], end='\\n\\n')\n",
    "\n",
    "    return ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to update ratings based on results data\n",
    "def update_league_ratings_single_game(HomeLeague, AwayLeague, FTHG, FTAG, league_ratings, rates):\n",
    "\n",
    "    #lambda: Determines to what extent the new match results influence the team ratings (could be improved to include temporal difference between matches)\n",
    "    #learning_rate_lambda = 0.054\n",
    "    learning_rate_lambda = rates['lambda2']\n",
    "\n",
    "    #psi: diminish the impact each additional goal difference error has on team ratings\n",
    "    diminishing_function_psi = lambda error: 3 * np.log10(1 + error)\n",
    "\n",
    "    #gamma: determines to what extent performances at the home grounds influence away team ratings and vice versa\n",
    "    #learning_rate_gamma = 0.79\n",
    "    learning_rate_gamma = rates['gamma2']\n",
    "\n",
    "    #print(HomeTeam, \"-\", AwayTeam, FTHG, \":\", FTAG)\n",
    "\n",
    "\n",
    "    observed_goal_difference = FTHG - FTAG\n",
    "    #print(\"Observed Goal Difference:\", observed_goal_difference)\n",
    "\n",
    "    #Calculate expected goals for home team\n",
    "    #expected_goal_x = round((10 ** (abs(ratings[HomeTeam]['brH']) / 3)) - 1,5)\n",
    "    expected_goal_x_temp = abs(league_ratings[HomeLeague]['brH']) / 3\n",
    "    expected_goal_x = np.sign(league_ratings[HomeLeague]['brH']) * (np.power(10, expected_goal_x_temp) - 1)\n",
    "    #print(\"Expected Goals x:\", expected_goal_x)\n",
    "\n",
    "    # Calculate expected goals for away team\n",
    "    #expected_goal_y = round((10 ** (abs(ratings[AwayTeam]['brA']) / 3)) - 1,5)\n",
    "    expected_goal_y_temp = abs(league_ratings[AwayLeague]['brA']) / 3\n",
    "    expected_goal_y = np.sign(league_ratings[AwayLeague]['brA']) * (np.power(10, expected_goal_y_temp) - 1)\n",
    "    #print(\"Expected Goals y:\", expected_goal_y)\n",
    "\n",
    "    # Calculate expected goal difference based on ratings\n",
    "    expected_goal_difference = expected_goal_x - expected_goal_y\n",
    "    #print(\"Expected Goal Difference:\", expected_goal_difference)\n",
    "\n",
    "    # Calculate the error between observed and expected goal difference\n",
    "    error = abs(observed_goal_difference - expected_goal_difference)\n",
    "    #print(\"error:\", error)\n",
    "\n",
    "    psi_temp = diminishing_function_psi(error)\n",
    "\n",
    "    # Diminish the impact of the goal difference error for both teams x and y respectively\n",
    "    if (expected_goal_difference < observed_goal_difference):\n",
    "        diminishing_function_psi_x = psi_temp\n",
    "        diminishing_function_psi_y = -psi_temp\n",
    "    else:\n",
    "        diminishing_function_psi_x = -psi_temp\n",
    "        diminishing_function_psi_y = psi_temp\n",
    "    #print(\"Diminishing Function psi x:\", diminishing_function_psi_x)\n",
    "    #print(\"Diminishing Function psi y:\", diminishing_function_psi_y)\n",
    "\n",
    "    # Update the home team x background ratings\n",
    "    previous_home_rating_x = league_ratings[HomeLeague]['brH']\n",
    "    previous_away_rating_x = league_ratings[HomeLeague]['brA']\n",
    "    #print(\"Old brH x:\", previous_home_rating_x)\n",
    "    #print(\"Old brA x:\", previous_away_rating_x)\n",
    "\n",
    "    league_ratings[HomeLeague]['brH'] = previous_home_rating_x + diminishing_function_psi_x * learning_rate_lambda\n",
    "    league_ratings[HomeLeague]['brA'] = previous_away_rating_x + (league_ratings[HomeLeague]['brH'] - previous_home_rating_x) * learning_rate_gamma\n",
    "    #print(\"New brH x:\", ratings[HomeTeam]['brH'])\n",
    "    #print(\"New brA x:\", ratings[HomeTeam]['brA'])\n",
    "\n",
    "    # Update the away team y background ratings\n",
    "    previous_home_rating_y = league_ratings[AwayLeague]['brH']\n",
    "    previous_away_rating_y = league_ratings[AwayLeague]['brA']\n",
    "    #print(\"Old brH y:\", previous_home_rating_y)\n",
    "    #print(\"Old brA y:\", previous_away_rating_y)\n",
    "\n",
    "    league_ratings[AwayLeague]['brA'] = previous_away_rating_y + diminishing_function_psi_y * learning_rate_lambda\n",
    "    league_ratings[AwayLeague]['brH'] = previous_home_rating_y + (league_ratings[AwayLeague]['brA'] - previous_away_rating_y) * learning_rate_gamma\n",
    "    #print(\"New brH y:\", ratings[AwayTeam]['brH'])\n",
    "    #print(\"New brA y:\", ratings[AwayTeam]['brA'])\n",
    "\n",
    "    #print(\"Old overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"Old overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'])\n",
    "\n",
    "    # Update the continuous over/underperformances for the home team\n",
    "    if (observed_goal_difference > expected_goal_difference):\n",
    "        league_ratings[HomeLeague]['continuous_overunderperformances'] = max(1, league_ratings[HomeLeague]['continuous_overunderperformances'] + 1)\n",
    "        league_ratings[AwayLeague]['continuous_overunderperformances'] = min(-1, league_ratings[AwayLeague]['continuous_overunderperformances'] - 1)\n",
    "    elif (observed_goal_difference < expected_goal_difference):\n",
    "        league_ratings[HomeLeague]['continuous_overunderperformances'] = min(-1, league_ratings[HomeLeague]['continuous_overunderperformances'] - 1)\n",
    "        league_ratings[AwayLeague]['continuous_overunderperformances'] = max(1, league_ratings[AwayLeague]['continuous_overunderperformances'] + 1)\n",
    "    else:\n",
    "        league_ratings[HomeLeague]['continuous_overunderperformances'] = 0\n",
    "        league_ratings[AwayLeague]['continuous_overunderperformances'] = 0\n",
    "\n",
    "    #print(\"New overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"New overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'], end='\\n\\n')\n",
    "\n",
    "    return league_ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_provisional_ratings(ratings, team, competition, rates):\n",
    "\n",
    "    #phi: Represents the number of continuous performances, above or below expectations, which do not trigger the form factor\n",
    "    #form_threshold_phi = 1\n",
    "    form_threshold_phi = rates['phi']\n",
    "\n",
    "    #mu: represents the rating difference used to establish provisional ratings from background ratings\n",
    "    #rating_impact_mu = 0.01\n",
    "    rating_impact_mu = rates['mu']\n",
    "\n",
    "    #delta: the level by which rating impact μ diminishes with each additional continuous over/under-performance\n",
    "    #diminishing_factor_delta = 2.5\n",
    "    diminishing_factor_delta = rates['delta']\n",
    "\n",
    "    brH = ratings[team][competition]['brH']  # Background rating home\n",
    "    brA = ratings[team][competition]['brA']  # Background rating away\n",
    "    prH = brH\n",
    "    prA = brA\n",
    "\n",
    "    return prH, prA\n",
    "\n",
    "    if abs(ratings[team][competition]['continuous_overunderperformances']) < (form_threshold_phi + 1):\n",
    "        return prH, prA\n",
    "\n",
    "    # Calculate performance factor for home team x\n",
    "    a = abs(ratings[team][competition]['continuous_overunderperformances']) - form_threshold_phi\n",
    "    b = a ** diminishing_factor_delta\n",
    "    form_factor_home = a / b\n",
    "\n",
    "    # Calculate provisional rating of the team\n",
    "    if (ratings[team][competition]['continuous_overunderperformances'] > form_threshold_phi):\n",
    "        prH = brH + rating_impact_mu * form_factor_home\n",
    "        prA = brA + rating_impact_mu * form_factor_home\n",
    "    if (ratings[team][competition]['continuous_overunderperformances'] < -form_threshold_phi):\n",
    "        prH = brH - rating_impact_mu * form_factor_home\n",
    "        prA = brA - rating_impact_mu * form_factor_home\n",
    "\n",
    "    #return prH, prA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_probabilities(features, model):\n",
    "\n",
    "    new_game_rating_difference = np.array([features])\n",
    "    probabilities = model.predict_proba(new_game_rating_difference)\n",
    "    return probabilities[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to calculate the rating difference between two teams\n",
    "def calculate_rating_difference(HomeTeam, AwayTeam, competition, ratings, league_ratings, HomeLeague, Awayleague, rates):\n",
    "    rho = rates['rho']\n",
    "    sigma = rates['sigma']\n",
    "    \n",
    "    competition1 = competition\n",
    "    competition2 = competition\n",
    "    if competition == 'INT1':\n",
    "        competition1 = HomeLeague\n",
    "        competition2 = Awayleague\n",
    "        \n",
    "    # Calculate home team rating\n",
    "    home_rating_x = ratings[HomeTeam][competition1]['brH']\n",
    "    if (abs(ratings[HomeTeam][competition1]['continuous_overunderperformances']) > 1):\n",
    "        provisional_ratings_x = calculate_provisional_ratings(ratings, HomeTeam, competition1, rates)\n",
    "        home_rating_x = provisional_ratings_x[0]\n",
    "\n",
    "    # Calculate away team rating\n",
    "    away_rating_y = ratings[AwayTeam][competition2]['brA']\n",
    "    if (abs(ratings[AwayTeam][competition2]['continuous_overunderperformances']) > 1):\n",
    "        provisional_ratings_y = calculate_provisional_ratings(ratings, AwayTeam, competition2, rates)\n",
    "        away_rating_y = provisional_ratings_y[1]\n",
    "    \n",
    "    if competition == 'INT1':\n",
    "        home_rating_x = rho * home_rating_x + sigma * league_ratings[competition1]['brH']\n",
    "        away_rating_y = rho * away_rating_y + sigma * league_ratings[competition2]['brA']\n",
    "\n",
    "    # Calculate rating difference\n",
    "    rating_difference = home_rating_x - away_rating_y\n",
    "\n",
    "    return rating_difference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_outcomes(df_fixtures, ratings, rates, model):\n",
    "    \n",
    "    all_rps = []\n",
    "    league_ratings_fake = {}\n",
    "    HomeLeague = 'fake'\n",
    "    Awayleague = 'fake'\n",
    "\n",
    "    for index, row in df_fixtures.iterrows():\n",
    "        HomeTeam = row['HomeTeam']\n",
    "        AwayTeam = row['AwayTeam']\n",
    "        competition = row['Div']\n",
    "\n",
    "        # Initialize league table for the competition if it doesn't exist\n",
    "        if competition not in league_tables:\n",
    "            league_tables[competition] = pd.DataFrame(columns=['team', 'games_played', 'points'])\n",
    "\n",
    "\n",
    "        rating_difference = calculate_rating_difference(HomeTeam, AwayTeam, competition, ratings, league_ratings_fake, HomeLeague, Awayleague, rates)\n",
    "\n",
    "        #features = [prH_x, prA_x, prH_y, prA_y]\n",
    "        features = [rating_difference]\n",
    "\n",
    "        away_win_prob, draw_prob, home_win_prob = calculate_probabilities(features, model)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        FTHG = int(row['FTHG'])\n",
    "        FTAG = int(row['FTAG'])\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"{HomeTeam} - {AwayTeam} {FTHG}:{FTAG}\")\n",
    "        print(f\"Home Win Prob: {home_win_prob}\")\n",
    "        print(f\"Draw Prob: {draw_prob}\")\n",
    "        print(f\"Away Win Prob: {away_win_prob}\", end='\\n\\n')\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Call Ranked Probability Score function\n",
    "        probs = [home_win_prob, draw_prob, away_win_prob]\n",
    "        if row[\"FTR\"] == \"H\":\n",
    "            outcome = [1, 0, 0]\n",
    "        elif row[\"FTR\"] == \"D\":\n",
    "            outcome = [0, 1, 0]\n",
    "        else:\n",
    "            outcome = [0, 0, 1]\n",
    "\n",
    "        rps_score = rps(probs, outcome)\n",
    "        #print(\"RPS Score:\", rps_score, end='\\n\\n')\n",
    "        all_rps.append(rps_score)\n",
    "\n",
    "        # Update league table\n",
    "        league_tables[competition] = update_league_table(league_tables[competition], HomeTeam, AwayTeam, home_win_prob, draw_prob, away_win_prob)\n",
    "\n",
    "        # Update ratings\n",
    "        ratings = update_ratings_single_game(HomeTeam, AwayTeam, row['FTHG'], row['FTAG'], ratings, rates, competition)\n",
    "\n",
    "    print(f\"Average RPS Score for {competition}:\", np.mean(all_rps), '\\n')\n",
    "\n",
    "    # Sort all league tables\n",
    "    for competition, table in league_tables.items():\n",
    "        assert isinstance(table, pd.DataFrame), f\"Unexpected object: {type(table)} for competition: {competition}\"\n",
    "        table = table.sort_values(['points', 'games_played'], ascending=False)\n",
    "        table = table.reset_index(drop=True)\n",
    "        league_tables[competition] = table\n",
    "\n",
    "    return all_rps, league_tables\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_outcomes_int(df_int_fixtures, ratings, league_ratings, rates, model):\n",
    "\n",
    "    int_rps = []\n",
    "    \n",
    "    for index, row in df_int_fixtures.iterrows():\n",
    "        HomeTeam = row['HomeTeam']\n",
    "        AwayTeam = row['AwayTeam']\n",
    "        HomeLeague = row['HomeDiv']\n",
    "        Awayleague = row['AwayDiv']\n",
    "\n",
    "        competition = row['Div']\n",
    "\n",
    "        \n",
    "        rating_difference = calculate_rating_difference(HomeTeam, AwayTeam, competition, ratings, league_ratings, HomeLeague, Awayleague, rates)\n",
    "\n",
    "        #features = [prH_x, prA_x, prH_y, prA_y]\n",
    "        features = [rating_difference]\n",
    "\n",
    "        away_win_prob, draw_prob, home_win_prob = calculate_probabilities(features, model)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        FTHG = int(row['FTHG'])\n",
    "        FTAG = int(row['FTAG'])\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"{HomeTeam} - {AwayTeam} {FTHG}:{FTAG}\")\n",
    "        print(f\"Home Win Prob: {home_win_prob}\")\n",
    "        print(f\"Draw Prob: {draw_prob}\")\n",
    "        print(f\"Away Win Prob: {away_win_prob}\", end='\\n')\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # Call Ranked Probability Score function\n",
    "        probs = [home_win_prob, draw_prob, away_win_prob]\n",
    "        if row[\"FTR\"] == \"H\":\n",
    "            outcome = [1, 0, 0]\n",
    "        elif row[\"FTR\"] == \"D\":\n",
    "            outcome = [0, 1, 0]\n",
    "        else:\n",
    "            outcome = [0, 0, 1]\n",
    "\n",
    "        rps_score = rps(probs, outcome)\n",
    "        #print(\"RPS Score:\", rps_score, end='\\n\\n')\n",
    "        int_rps.append(rps_score)\n",
    "\n",
    "        # Update league_ratings\n",
    "        #league_ratings = update_league_ratings_single_game(HomeLeague, AwayLeague, row['FTHG'], row['FTAG'], league_ratings, rates)\n",
    "        \n",
    "\n",
    "    print(f\"RPS for {competition}:\", np.mean(int_rps), '\\n')\n",
    "\n",
    "\n",
    "    return int_rps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_league_table(league_table, HomeTeam, AwayTeam, home_win_prob, draw_prob, away_win_prob):\n",
    "\n",
    "    # Calculate points based on probabilities\n",
    "    home_points = home_win_prob * 3 + draw_prob * 1\n",
    "    away_points = away_win_prob * 3 + draw_prob * 1\n",
    "\n",
    "    # Home team update\n",
    "    if HomeTeam in league_table['team'].values:\n",
    "        league_table.loc[league_table['team'] == HomeTeam, 'games_played'] += 1\n",
    "        league_table.loc[league_table['team'] == HomeTeam, 'points'] += home_points\n",
    "    else:\n",
    "        df_home = pd.DataFrame({'team': [HomeTeam], 'games_played': [1], 'points': [home_points]})\n",
    "        league_table = pd.concat([league_table, df_home], ignore_index=True)\n",
    "\n",
    "    # Away team update\n",
    "    if AwayTeam in league_table['team'].values:\n",
    "        league_table.loc[league_table['team'] == AwayTeam, 'games_played'] += 1\n",
    "        league_table.loc[league_table['team'] == AwayTeam, 'points'] += away_points\n",
    "    else:\n",
    "        df_away = pd.DataFrame({'team': [AwayTeam], 'games_played': [1], 'points': [away_points]})\n",
    "        league_table = pd.concat([league_table, df_away], ignore_index=True)\n",
    "\n",
    "    return league_table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rps(probs, outcome):\n",
    "    cum_probs = np.cumsum(probs)\n",
    "    cum_outcomes = np.cumsum(outcome)\n",
    "\n",
    "    sum_rps = 0\n",
    "    for i in range(len(outcome)):\n",
    "        sum_rps+= (cum_probs[i] - cum_outcomes[i])**2\n",
    "\n",
    "    return sum_rps/(len(outcome)-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def train_model(df_train):\n",
    "\n",
    "    # Create Logistic Regression model\n",
    "    model = LogisticRegression(solver=\"saga\", penalty=\"l2\")  \n",
    "    #model = MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(5, 2), max_iter=1000, random_state=23)\n",
    "\n",
    "    # Reshape rating_difference to 2D array for model fitting\n",
    "    #X = df_train[['prH_x', 'prA_x', \"prH_y\", \"prA_y\"]].values\n",
    "    X = df_train[\"rating_difference\"].values.reshape(-1, 1)\n",
    "    y = df_train['FTR']\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and label encoder here\n",
    "    joblib.dump(model, '../Models/model.pkl')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    #score = model.score(X_test, y_test)\n",
    "    #print(f'Model accuracy: {score*100:.2f}%')\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Main Function\n",
    "\n",
    "# Load the results data file for seasons 2010-2011 to 2021-2022\n",
    "df_results = pd.read_csv('../data/new_season_2016-2022_sorted_compressed.csv')\n",
    "\n",
    "# Load the fixtures data file for the season 2022-2023\n",
    "df_fixtures = pd.read_csv('../data/new_season_2022-2023_sorted_top.csv')\n",
    "\n",
    "# Load the international results data file\n",
    "df_int_results = pd.read_csv('../data/new_season_2016-2022_INT.csv')\n",
    "\n",
    "# Load the international fixtures data file\n",
    "df_int_fixtures = pd.read_csv('../data/new_season_2022-2023_INT.csv')\n",
    "\n",
    "# Define the learning rates\n",
    "rates = {\n",
    "    'lambda': 0.04,\n",
    "    'gamma': 0.96,\n",
    "    'delta': 13,\n",
    "    'phi': 2,\n",
    "    'mu': 0.06,\n",
    "    'rho': 0.93,\n",
    "    'sigma': 0.6,\n",
    "    'ind_threshold': 0,\n",
    "    'lambda2': 0.15,\n",
    "    'gamma2': 0.97,\n",
    "    'x': 1.3,\n",
    "    'y' : 1.0,\n",
    "    'a' : -1.625,\n",
    "    'b' : 0.75\n",
    "}\n",
    "\n",
    "# Map teams to leagues\n",
    "df_int = pd.concat([df_int_results, df_int_fixtures], ignore_index=True)\n",
    "#team_to_league, rest_teams = create_team_to_league_mapping(df_results, df_fixtures, df_int)\n",
    "\n",
    "# Initialize ratings based on the results data\n",
    "ratings, league_ratings = initialize_ratings(df_results, df_fixtures, df_int_results, df_int_fixtures)\n",
    "\n",
    "# Update ratings based on the results data here\n",
    "ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, rates)\n",
    "#model.C_\n",
    "\n",
    "# Train the model for predicting match outcomes\n",
    "df_train = pd.DataFrame(training_games)\n",
    "#df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "model = train_model(df_train)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Create a reverse mapping of leagues to teams\n",
    "league_to_teams = {}\n",
    "for team, league in team_to_league.items():\n",
    "    if league not in league_to_teams:\n",
    "        league_to_teams[league] = []\n",
    "    league_to_teams[league].append(team)\n",
    "\n",
    "# Print the teams sorted by league\n",
    "for league, teams in sorted(league_to_teams.items()):\n",
    "    print(f\"{league}:\")\n",
    "    print(\", \".join(teams))\n",
    "    print()\n",
    "\"\"\"\n",
    "\n",
    "# Update league ratings based on the results data here\n",
    "league_ratings = update_league_ratings_multiple_games(df_int_results, league_ratings, rates)\n",
    "for league, values in league_ratings.items():\n",
    "    if values['brH'] != 0:\n",
    "        print(f\"League: {league}, Rating: {values['brH']}\")\n",
    "\n",
    "# Initialize an empty league tables dictionary and rps list\n",
    "league_tables = {}\n",
    "all_rps = []\n",
    "\n",
    "# Predict the probabilities of home win, draw and away win for the fixtures data\n",
    "for competition in df_fixtures['Div'].unique():\n",
    "    competition_fixtures = df_fixtures[df_fixtures['Div'] == competition]\n",
    "    competition_rps, league_tables = predict_outcomes(competition_fixtures, ratings, rates, model)\n",
    "    all_rps.extend(competition_rps)  # extend the list with rps scores from the current competition\n",
    "\n",
    "# Now you can calculate the mean RPS across all competitions\n",
    "mean_rps = np.mean(all_rps)\n",
    "print(\"Average RPS Score across all competitions:\", mean_rps)\n",
    "\n",
    "\n",
    "int_rps = predict_outcomes_int(df_int_fixtures, ratings, league_ratings, rates, model)\n",
    "\n",
    "\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gridsearch on x and y; a and b\n",
    "\n",
    "# Initialize the rates\n",
    "\n",
    "\n",
    "# Define a parameter grid with the ranges for your parameters\n",
    "param_grid = {\n",
    "    'x': np.linspace(1.0, 1.4, 5),\n",
    "    'y': np.linspace(1.0, 1.0, 1),\n",
    "    'a': np.linspace(-1.625, -1.625, 1),\n",
    "    'b': np.linspace(0.75, 0.75, 1)\n",
    "\n",
    "}\n",
    "\n",
    "# Create a ParameterGrid object from the dictionary\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Initialize the best_score variable\n",
    "best_score = float('inf')  # assuming lower scores are better\n",
    "\n",
    "# Create an empty list to store the results\n",
    "gs_results = []\n",
    "\n",
    "# Loop over the parameter combinations\n",
    "for params in tqdm.tqdm(grid):\n",
    "    # Update the rates dictionary\n",
    "    rates.update(params)\n",
    "    \n",
    "    ratings, league_ratings = initialize_ratings(df_results, df_fixtures, df_int_results, df_int_fixtures)\n",
    "    \n",
    "    # Re-train model with the new parameters\n",
    "    ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, rates)\n",
    "\n",
    "    df_train = pd.DataFrame(training_games)\n",
    "    #df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "    model = train_model(df_train)\n",
    "\n",
    "    all_rps, league_tables = predict_outcomes(df_fixtures, ratings, rates, model)\n",
    "    score = np.mean(all_rps)\n",
    "\n",
    "    # Store the current results\n",
    "    gs_results.append({\n",
    "        'x': rates['x'],\n",
    "        'y': rates['y'],\n",
    "        'a': rates['a'],\n",
    "        'b': rates['b'],\n",
    "        'score': score,\n",
    "    })\n",
    "\n",
    "# Sort the results based on the score and get the top 5\n",
    "top_5_combinations = sorted(gs_results, key=lambda z: z['score'])[:5]\n",
    "\n",
    "print(\"Top 5 combinations:\")\n",
    "for combo in top_5_combinations:\n",
    "    print(f\"x: {combo['x']}, y: {combo['y']}, a: {combo['a']}, b: {combo['b']}, Score: {combo['score']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "competitions = set(df_results['Div']).union(set(df_fixtures['Div'])).union(set(df_int['HomeDiv'])).union(set(df_int['AwayDiv']))\n",
    "for competition in competitions:\n",
    "    print(competition,':', ratings['Watford'][competition])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "                 \n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.annotate(\"Background Rating over time\", (0.5, 1.05), xycoords='axes fraction', ha='center', va='center', size=16)\n",
    "df_ratings = pd.DataFrame(games_with_ratings)\n",
    "teams = [\"Arsenal\", \"Man City\", \"Man United\", \"Chelsea\", \"Tottenham\", \"Liverpool\", \"Everton\", \"Leicester\", \"West Ham\", \"Southampton\"]\n",
    "#teams = ['Arsenal', 'Man City', 'Barcelona', 'Real Madrid', 'Bayern Munich', 'Dortmund', 'Paris SG', 'Napoli', 'Juventus']\n",
    "#teams = league_to_teams['E0']\n",
    "#for team in df_ratings[\"team\"].unique()[:10]:\n",
    "for team in teams:\n",
    "    per_team = df_ratings.loc[df_ratings[\"team\"] == team]\n",
    "    plt.plot((per_team[\"home_rating\"] + per_team[\"away_rating\"]) / 2, label=team)\n",
    "plt.legend()\n",
    "plt.savefig(\"../images/ratings_over_time232.png\", dpi=300)\n",
    "\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print league tables\n",
    "for competition, league_table in league_tables.items():\n",
    "    print(f\"League table for {competition}:\")\n",
    "    league_table_df = league_table.copy()  # creating a copy to avoid modifying the original data\n",
    "    league_table_df.index = league_table_df.index + 1\n",
    "    print(league_table_df)\n",
    "    league_table_df.index = league_table_df.index - 1\n",
    "\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot RPS distribution\n",
    "plt.annotate(\"RPS Distribution\", (0.5, 0.9), xycoords='axes fraction', ha='center', va='center', size=16)\n",
    "plt.hist(all_rps, bins=25)\n",
    "plt.savefig(\"../images/rps_distribution232.png\", dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for team, team_ratings in ratings.items():\n",
    "    print(f\"Team: {team}\")\n",
    "    print(f\"Background Rating Home: {team_ratings['brH']}\")\n",
    "    print(f\"Background Rating Away: {team_ratings['brA']}\")\n",
    "    print(f\"Continuous Over/Underperformances: {team_ratings['continuous_overunderperformances']}\")\n",
    "    print()\n",
    "\"\"\"\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gridsearch on lambda and gamma\n",
    "\n",
    "# Initialize the rates\n",
    "\n",
    "\n",
    "# Define a parameter grid with the ranges for your parameters\n",
    "param_grid = {\n",
    "    'lambda': np.linspace(0.033, 0.041, int((0.041 - 0.033) / 0.001) + 1),\n",
    "    'gamma': np.linspace(0.95, 1.0, int((1.0 - 0.95) / 0.01) + 1)\n",
    "\n",
    "}\n",
    "\n",
    "# Create a ParameterGrid object from the dictionary\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Initialize the best_score variable\n",
    "best_score = float('inf')  # assuming lower scores are better\n",
    "\n",
    "# Create an empty list to store the results\n",
    "gs_results = []\n",
    "\n",
    "# Loop over the parameter combinations\n",
    "for params in tqdm.tqdm(grid):\n",
    "    # Update the rates dictionary\n",
    "    rates.update(params)\n",
    "    \n",
    "    ratings, league_ratings = initialize_ratings(df_results, df_fixtures)\n",
    "    \n",
    "    # Re-train model with the new parameters\n",
    "    ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, rates)\n",
    "\n",
    "    df_train = pd.DataFrame(training_games)\n",
    "    #df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "    model = train_model(df_train)\n",
    "\n",
    "    all_rps, league_tables = predict_outcomes(df_fixtures, ratings, rates, model)\n",
    "    score = np.mean(all_rps)\n",
    "\n",
    "    # Store the current results\n",
    "    gs_results.append({\n",
    "        'lambda': rates['lambda'],\n",
    "        'gamma': rates['gamma'],\n",
    "        'score': score,\n",
    "    })\n",
    "\n",
    "# Sort the results based on the score and get the top 5\n",
    "top_5_combinations = sorted(gs_results, key=lambda x: x['score'])[:5]\n",
    "\n",
    "print(\"Top 5 combinations:\")\n",
    "for combo in top_5_combinations:\n",
    "    print(f\"Lambda: {combo['lambda']}, Gamma: {combo['gamma']}, Score: {combo['score']}\")\n",
    "\n",
    "# Convert the gs_results to a DataFrame and plot them\n",
    "df_gs_results = pd.DataFrame(gs_results)\n",
    "\n",
    "# Define grid of x, y values\n",
    "lambda_range = np.linspace(df_gs_results['lambda'].min(), df_gs_results['lambda'].max(), num=50)\n",
    "gamma_range = np.linspace(df_gs_results['gamma'].min(), df_gs_results['gamma'].max(), num=50)\n",
    "lambda_grid, gamma_grid = np.meshgrid(lambda_range, gamma_range)\n",
    "\n",
    "# Interpolate z values for this grid\n",
    "rps_grid = griddata((df_gs_results['lambda'], df_gs_results['gamma']), df_gs_results['score'], (lambda_grid, gamma_grid), method='cubic')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create 3D surface plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(lambda_grid, gamma_grid, rps_grid, cmap='RdYlGn_r', edgecolor='none')\n",
    "ax.set_xlabel('Lambda')\n",
    "ax.set_ylabel('Gamma')\n",
    "ax.set_zlabel('RPS Score', fontsize=10, labelpad=5)\n",
    "ax.invert_zaxis()  # To make lower scores appear higher\n",
    "#fig.colorbar(surf)\n",
    "plt.savefig(\"../images/3d_plot_gs232.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create 2D plot with colormap\n",
    "plt.figure(figsize=(10, 10))  # Adjust figsize to your preference to make the plot square\n",
    "plt.title('Grid Search Scores')\n",
    "\n",
    "cmap_reversed = plt.cm.get_cmap('RdYlGn_r')  # Reversed Red-Yellow-Green colormap\n",
    "\n",
    "# Here we store the image object returned by imshow\n",
    "im = plt.imshow(rps_grid, interpolation='nearest', cmap=cmap_reversed,\n",
    "           extent=(param_grid['learning_rate_lambda'].min(), param_grid['learning_rate_lambda'].max(), param_grid['learning_rate_gamma'].min(), param_grid['learning_rate_gamma'].max()), origin='lower')\n",
    "\n",
    "# We use the stored image object for the colorbar\n",
    "plt.colorbar(im, cmap=cmap_reversed)\n",
    "\n",
    "plt.axis('square')  # This will enforce a square aspect ratio\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Gamma\")\n",
    "plt.savefig(\"../images/2d_plot_heat_gs232.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Convert grid search results into a pivot table for plotting\n",
    "pivot_table = df_gs_results.pivot('learning_rate_lambda', 'learning_rate_gamma', 'score')\n",
    "\n",
    "# Create contour plot\n",
    "plt.figure(figsize=(10,7))\n",
    "contour_plot = plt.contourf(pivot_table.columns, pivot_table.index, pivot_table.values, cmap='RdYlGn_r', levels=100)\n",
    "plt.title('Grid Search RPS Scores')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Gamma')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(contour_plot)\n",
    "cbar.ax.set_ylabel('RPS Score')\n",
    "\n",
    "plt.savefig(\"../images/2d_plot_contour_gs232.png\", dpi=300)\n",
    "plt.show()\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Potential values for lambda2 and gamma2\n",
    "potential_lambda2_values = np.linspace(0.1, 0.2, num=11)  \n",
    "potential_gamma2_values = np.linspace(0.9, 1.0, num=11)  \n",
    "\n",
    "# Lists to hold the parameter 'lambda2', 'gamma2' and the corresponding RPS values\n",
    "parameter_values = []\n",
    "rps_values = []\n",
    "\n",
    "# Iterate over potential lambda2 and gamma2 values\n",
    "for lambda2 in potential_lambda2_values:\n",
    "    for gamma2 in potential_gamma2_values:\n",
    "        _, league_ratings = initialize_ratings(df_results, df_fixtures, df_int_results, df_int_fixtures)\n",
    "        \n",
    "        # Update rates dictionary with the current lambda2 and gamma2 values\n",
    "        rates['lambda2'] = lambda2\n",
    "        rates['gamma2'] = gamma2\n",
    "\n",
    "        # ... [Your existing code to update ratings and calculate RPS]\n",
    "        league_ratings = update_league_ratings_multiple_games(df_int_results, league_ratings, rates)\n",
    "        int_rps = predict_outcomes_int(df_int_fixtures, ratings, league_ratings, rates, model)\n",
    "        # Calculate the mean RPS score for this combination\n",
    "        mean_rps = np.mean(int_rps)\n",
    "        \n",
    "        # Store the lambda2, gamma2, and corresponding RPS value\n",
    "        parameter_values.append((lambda2, gamma2))\n",
    "        rps_values.append(mean_rps)\n",
    "\n",
    "# Identify top 5 parameter combinations\n",
    "top_indices = np.argsort(rps_values)[:5]  # gets the indices of the 5 lowest RPS scores\n",
    "top_parameters = [parameter_values[i] for i in top_indices]\n",
    "top_rps_values = [rps_values[i] for i in top_indices]\n",
    "\n",
    "# Print top 5 parameter combinations\n",
    "for i in range(5):\n",
    "    print(f\"Rank {i+1}, Parameters (lambda2, gamma2): {top_parameters[i]}, RPS Score: {top_rps_values[i]}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def optimize_int_threshold(df_results, df_fixtures, rates):\n",
    "    # Define range for int_threshold\n",
    "    thresholds = np.arange(5000, 45000, 5000)  \n",
    "\n",
    "    # Initialize the best_score variable\n",
    "    best_score = float('inf')  \n",
    "\n",
    "    # Create an empty list to store the results\n",
    "    optimization_results = []\n",
    "\n",
    "    for threshold in tqdm.tqdm(thresholds):\n",
    "        # Update rates with the current threshold\n",
    "        rates['int_threshold'] = threshold\n",
    "\n",
    "        ratings, league_ratings = initialize_ratings(df_results, df_fixtures)\n",
    "        \n",
    "        # Train and evaluate your model with the current threshold\n",
    "        ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, rates)\n",
    "        \n",
    "        df_train = pd.DataFrame(training_games)\n",
    "        df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "        model = train_model(df_train)\n",
    "\n",
    "        all_rps, league_tables = predict_outcomes(df_fixtures, ratings, rates, model)\n",
    "        score = np.mean(all_rps)\n",
    "\n",
    "        # If the current score is better than the best_score, update best_score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "        # Store the current score and threshold\n",
    "        optimization_results.append({\n",
    "            'int_threshold': threshold,\n",
    "            'score': score,\n",
    "        })\n",
    "\n",
    "    # Convert the results to a DataFrame and sort by score\n",
    "    df_optimization_results = pd.DataFrame(optimization_results).sort_values(by='score', ascending=True)\n",
    "\n",
    "    # Display the top 5 combinations of the threshold and their score\n",
    "    print(df_optimization_results.head())\n",
    "\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# Call the function and get the best threshold and its score\n",
    "best_threshold, best_score = optimize_int_threshold(df_results, df_fixtures, rates)\n",
    "print(f\"Best int_threshold: {best_threshold}\")\n",
    "print(f\"Best score: {best_score}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 1. Define the parameter grid\n",
    "param_grid = {\n",
    "    'mu': np.linspace(0.06, 0.08, 3),  # This gives 31 steps, starting from 0 to 0.03 inclusive\n",
    "    'phi': np.linspace(1, 3, 3),  # This gives 41 steps, starting from 0 to 4 inclusive\n",
    "    'delta': np.linspace(11, 13, 3)  # This gives 21 steps, starting from 1 to 3 inclusive\n",
    "}\n",
    "\n",
    "# Initialize the best_score variable and best_params dictionary\n",
    "best_score = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Create an empty list to store the results\n",
    "gs_results = []\n",
    "\n",
    "# 2. Iterate over the parameter combinations\n",
    "for params in tqdm.tqdm(ParameterGrid(param_grid)):\n",
    "    # Extract rates from params and merge with the existing rates dictionary\n",
    "    current_rates = rates.copy()\n",
    "    current_rates.update(params)\n",
    "    \n",
    "    \n",
    "    # Train and predict with current_rates (and current_model if necessary)\n",
    "    ratings, league_ratings = initialize_ratings(df_results, df_fixtures)\n",
    "\n",
    "    # 3. Re-train model with the new parameters\n",
    "    ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, current_rates)\n",
    "\n",
    "    df_train = pd.DataFrame(training_games)\n",
    "    #df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "    current_model = train_model(df_train)\n",
    "    # If your training method updates the model based on rates, you should train it here\n",
    "    \n",
    "    all_rps, league_tables = predict_outcomes(df_fixtures, ratings, current_rates, current_model)\n",
    "    score = np.mean(all_rps)\n",
    "\n",
    "    # 4. If the current score is better than the best_score, update best_score and best_params\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "    # Store the current score and parameters\n",
    "    gs_results.append({\n",
    "        'mu': params['mu'],\n",
    "        'phi': params['phi'],\n",
    "        'delta': params['delta'],\n",
    "        'score': score,\n",
    "    })\n",
    "\n",
    "# 5. Identify the best parameters based on the score\n",
    "print(f'Best score: {best_score}')\n",
    "print(f'Best params: {best_params}')\n",
    "\n",
    "# Convert the gs_results to a DataFrame\n",
    "df_gs_results = pd.DataFrame(gs_results)\n",
    "\n",
    "# Sort the results by score and get the top 5\n",
    "top_5_results = df_gs_results.sort_values(by='score', ascending=True).head(5)\n",
    "\n",
    "print(\"Top 5 parameter combinations:\")\n",
    "print(top_5_results)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lists to hold the parameter 'rho', 'sigma' and the corresponding RPS values\n",
    "parameter_values = []\n",
    "rps_values = []\n",
    "\n",
    "# Grid of potential values for rho and sigma\n",
    "potential_rho_values = np.linspace(0.75, 1.0, num=26)\n",
    "potential_sigma_values = np.linspace(0.5, 0.7, num=21)\n",
    "\n",
    "# Iterate over potential rho and sigma values\n",
    "for rho in potential_rho_values:\n",
    "    for sigma in potential_sigma_values:\n",
    "        rates['rho'] = rho\n",
    "        rates['sigma'] = sigma\n",
    "        \n",
    "        # Obtain the RPS for the current value of rho and sigma\n",
    "        int_rps = predict_outcomes_int(df_int_fixtures, ratings, league_ratings, rates, model)\n",
    "\n",
    "        # Compute the average RPS\n",
    "        avg_rps = np.mean(int_rps)\n",
    "\n",
    "        # Add current result to the lists\n",
    "        parameter_values.append((rho, sigma))\n",
    "        rps_values.append(avg_rps)\n",
    "\n",
    "# Identify top 5 parameter combinations\n",
    "top_indices = np.argsort(rps_values)[:5]  # gets the indices of the 5 lowest RPS scores\n",
    "top_parameters = [parameter_values[i] for i in top_indices]\n",
    "top_rps_values = [rps_values[i] for i in top_indices]\n",
    "\n",
    "# Print top 5 parameter combinations\n",
    "for i in range(5):\n",
    "    print(f\"Rank {i+1}, Parameters (rho, sigma): {top_parameters[i]}, RPS Score: {top_rps_values[i]}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate meshgrid for 3D plot\n",
    "a_grid, b_grid = np.meshgrid(potential_a_values, potential_b_values)\n",
    "\n",
    "# Reshape rps_values into grid\n",
    "rps_grid = np.array(rps_values).reshape(a_grid.shape)\n",
    "\n",
    "# Create 3D surface plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(a_grid, b_grid, rps_grid, cmap='RdYlGn_r', edgecolor='none')\n",
    "ax.set_xlabel('a')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('RPS Score', fontsize=10, labelpad=5)\n",
    "ax.invert_zaxis()  # To make lower scores appear higher\n",
    "plt.savefig(\"../images/3d_plot_ab_rps.png\", dpi=300)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "a_values = [round(a, 2) for a in potential_a_values]\n",
    "b_values = [round(b, 2) for b in potential_b_values]\n",
    "\n",
    "# Reshape RPS values to the shape of the grid\n",
    "rps_grid = np.array(rps_values).reshape(len(a_values), len(b_values))\n",
    "\n",
    "# Create a dataframe from the grid\n",
    "df_rps = pd.DataFrame(rps_grid, index=a_values, columns=b_values)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(df_rps, cmap='RdYlGn_r', annot=False, fmt=\".3f\")\n",
    "plt.title('Heatmap of RPS scores for different values of \"a\" and \"b\"')\n",
    "plt.xlabel('b')\n",
    "plt.ylabel('a')\n",
    "\n",
    "# Invert y-axis\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.savefig(\"../images/heatmap_ab_rps.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "a_values = [round(a, 2) for a in potential_a_values]\n",
    "b_values = [round(b, 2) for b in potential_b_values]\n",
    "\n",
    "# Reshape RPS values to the shape of the grid\n",
    "rps_grid = np.array(rps_values).reshape(len(a_values), len(b_values))\n",
    "\n",
    "# Create a dataframe from the grid\n",
    "df_rps = pd.DataFrame(rps_grid, index=a_values, columns=b_values)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(df_rps, cmap='RdYlGn_r', annot=False, fmt=\".3f\")\n",
    "plt.title('Heatmap of RPS scores for different values of \"a\" and \"b\"')\n",
    "plt.xlabel('b')\n",
    "plt.ylabel('a')\n",
    "\n",
    "# Manually highlight the best area\n",
    "highlight_a = 0.25\n",
    "highlight_b = 1.05\n",
    "\n",
    "# Add a red rectangle around the cell to highlight it\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_visible(True)\n",
    "ax.add_patch(Rectangle((b_values.index(highlight_b), a_values.index(highlight_a)), 1, 1, fill=False, edgecolor='red', lw=3))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "plt.savefig(\"../images/heatmap_ab_rps1.png\", dpi=300)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "# Manually highlight the best area\n",
    "highlight_a = 0.25\n",
    "highlight_b = 1.05\n",
    "\n",
    "# Find indices of the desired range in a_values and b_values\n",
    "start_a_index = a_values.index(0)\n",
    "end_a_index = a_values.index(0.5) + 1  # plus 1 to include 0.5\n",
    "start_b_index = b_values.index(0.75)\n",
    "end_b_index = b_values.index(1.25) + 1  # plus 1 to include 1.25\n",
    "\n",
    "# Select subsets\n",
    "a_values_subset = a_values[start_a_index:end_a_index]\n",
    "b_values_subset = b_values[start_b_index:end_b_index]\n",
    "rps_grid_subset = rps_grid[start_a_index:end_a_index, start_b_index:end_b_index]\n",
    "\n",
    "# Create a heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "cax = ax.matshow(rps_grid_subset, origin='lower', cmap='RdYlGn_r')\n",
    "fig.colorbar(cax)\n",
    "# Move x-axis labels to bottom\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.set_xticks(range(len(b_values_subset)))\n",
    "ax.set_yticks(range(len(a_values_subset)))\n",
    "ax.set_xticklabels(np.round(b_values_subset, 2))\n",
    "ax.set_yticklabels(np.round(a_values_subset, 2))\n",
    "\n",
    "plt.title('Heatmap of RPS scores for different values of \"a\" and \"b\"')\n",
    "plt.xlabel('b')\n",
    "plt.ylabel('a')\n",
    "\n",
    "plt.savefig(\"../images/heatmap_ab_rps2.png\", dpi=300)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
