{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tqdm\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to initialize ratings\n",
    "def initialize_ratings(df_results, df_fixtures):\n",
    "    ratings = {}\n",
    "    league_ratings = {}\n",
    "\n",
    "    # Get the list of competitions\n",
    "    competitions = set(df_results['Div']).union(set(df_fixtures['Div']))\n",
    "\n",
    "    # Iterate over teams in the results data\n",
    "    teams = set(df_results['HomeTeam']).union(set(df_results['AwayTeam'])).union(set(df_fixtures['HomeTeam'])).union(set(df_fixtures['AwayTeam']))\n",
    "\n",
    "    for team in teams:\n",
    "        ratings[team] = {}\n",
    "\n",
    "        # Initialize ratings for each team for each competition\n",
    "        for competition in competitions:\n",
    "            ratings[team][competition] = {\n",
    "                'brH': 0.0,\n",
    "                'brA': 0.0,\n",
    "                'continuous_overunderperformances': 0\n",
    "            }\n",
    "    \n",
    "    # Initialize ratings for each competition\n",
    "    league_ratings['REST'] = {\n",
    "        'brH': 0.0,\n",
    "        'brA': 0.0,\n",
    "        'continuous_overunderperformances': 0\n",
    "    }\n",
    "    \n",
    "    for competition in competitions:\n",
    "        league_ratings[competition] = {\n",
    "            'brH': 0.0,\n",
    "            'brA': 0.0,\n",
    "            'continuous_overunderperformances': 0\n",
    "        }\n",
    "\n",
    "    print('Teams:', teams, end='\\n\\n')\n",
    "    return ratings, league_ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_team_to_league_mapping(df_results, df_fixtures, df_international):\n",
    "    team_to_league = {}\n",
    "    rest_teams = set() # To store teams that are assigned to the 'REST' league\n",
    "\n",
    "    def get_league_level(division):\n",
    "        # Extracting the integer part from the division\n",
    "        integer_part = ''.join(filter(str.isdigit, division))\n",
    "        return int(integer_part)\n",
    "\n",
    "\n",
    "    # Iterate through the results and fixtures dataframes and map teams to their leagues\n",
    "    for df in [df_results, df_fixtures]:\n",
    "        for index, row in df.iterrows():\n",
    "            for team in [row['HomeTeam'], row['AwayTeam']]:\n",
    "                current_div = row['Div']\n",
    "                current_level = get_league_level(current_div)\n",
    "\n",
    "                # If the team is not yet in the dictionary, or if the current league is higher, update the entry\n",
    "                if team not in team_to_league or current_level < get_league_level(team_to_league[team]):\n",
    "                    team_to_league[team] = current_div\n",
    "\n",
    "    # Now process df_international\n",
    "    for index, row in df_international.iterrows():\n",
    "        for team in [row['HomeTeam'], row['AwayTeam']]:\n",
    "            if team not in team_to_league:\n",
    "                # If the team is not found in the other dataframes, assign it to 'REST'\n",
    "                team_to_league[team] = 'REST'\n",
    "                rest_teams.add(team)\n",
    "\n",
    "    return team_to_league, rest_teams"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_league_from_team(team, team_to_league):\n",
    "    return team_to_league.get(team, 'REST')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to update ratings based on results data\n",
    "def update_ratings_multiple_games(df_results, ratings, learning_rate_lambda, learning_rate_gamma):\n",
    "\n",
    "    games_with_rating = []\n",
    "    training_games = []\n",
    "\n",
    "    # Iterate over each match in the results data\n",
    "    for index, row in df_results.iterrows():\n",
    "\n",
    "        # Identify the competition in which the match took place\n",
    "        competition = row['Div']\n",
    "\n",
    "        if index > 2500:\n",
    "            #add current game to training data\n",
    "            training_games.append({\n",
    "                \"brH_x\": ratings[row[\"HomeTeam\"]][competition][\"brH\"],\n",
    "                \"brA_x\": ratings[row[\"HomeTeam\"]][competition][\"brA\"],\n",
    "                \"prH_x\": calculate_provisional_ratings(ratings, row[\"HomeTeam\"], competition)[0],\n",
    "                \"prA_x\": calculate_provisional_ratings(ratings, row[\"HomeTeam\"], competition)[1],\n",
    "                \"brH_y\": ratings[row[\"AwayTeam\"]][competition][\"brH\"],\n",
    "                \"brA_y\": ratings[row[\"AwayTeam\"]][competition][\"brA\"],\n",
    "                \"prH_y\": calculate_provisional_ratings(ratings, row[\"AwayTeam\"], competition)[0],\n",
    "                \"prA_y\": calculate_provisional_ratings(ratings, row[\"AwayTeam\"], competition)[1],\n",
    "                \"rating_difference\": (calculate_provisional_ratings(ratings, row[\"HomeTeam\"], competition)[0]) - (calculate_provisional_ratings(ratings, row[\"AwayTeam\"], competition)[1]),\n",
    "                \"FTHG\": row[\"FTHG\"],\n",
    "                \"FTAG\": row[\"FTAG\"],\n",
    "                \"FTR\": row[\"FTR\"]\n",
    "            })\n",
    "\n",
    "\n",
    "        if np.isnan(ratings[row['HomeTeam']][competition]['brH']):\n",
    "            print(\"error\")\n",
    "            break\n",
    "\n",
    "        ratings = update_ratings_single_game(row['HomeTeam'], row['AwayTeam'], row['FTHG'], row['FTAG'], ratings, learning_rate_lambda, learning_rate_gamma, competition)\n",
    "\n",
    "        games_with_rating.append({\n",
    "            \"team\": row[\"HomeTeam\"],\n",
    "            \"home_rating\": ratings[row[\"HomeTeam\"]][competition][\"brH\"],\n",
    "            \"away_rating\": ratings[row[\"HomeTeam\"]][competition][\"brA\"],\n",
    "            \"continuous_overunderperformances\": ratings[row[\"HomeTeam\"]][competition][\"continuous_overunderperformances\"],\n",
    "        })\n",
    "\n",
    "        games_with_rating.append({\n",
    "            \"team\": row[\"AwayTeam\"],\n",
    "            \"home_rating\": ratings[row[\"AwayTeam\"]][competition][\"brH\"],\n",
    "            \"away_rating\": ratings[row[\"AwayTeam\"]][competition][\"brA\"],\n",
    "            \"continuous_overunderperformances\": ratings[row[\"AwayTeam\"]][competition][\"continuous_overunderperformances\"],\n",
    "        })\n",
    "\n",
    "    return ratings, games_with_rating, training_games"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_league_ratings_multiple_games(df_international, league_ratings, team_to_league, learning_rate_lambda, learning_rate_gamma):\n",
    "    # Iterate over each match in the international results data\n",
    "    for index, row in df_international.iterrows():\n",
    "        # Extract relevant information from the row\n",
    "        HomeLeague = get_league_from_team(row['HomeTeam'], team_to_league)\n",
    "        AwayLeague = get_league_from_team(row['AwayTeam'], team_to_league)\n",
    "        FTHG = row['FTHG']\n",
    "        FTAG = row['FTAG']\n",
    "\n",
    "        # Update the league ratings based on the match result\n",
    "        league_ratings = update_league_ratings_single_game(HomeLeague, AwayLeague, FTHG, FTAG, league_ratings, learning_rate_lambda, learning_rate_gamma)\n",
    "\n",
    "    return league_ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to update ratings based on results data\n",
    "def update_ratings_single_game(HomeTeam, AwayTeam, FTHG, FTAG, ratings, learning_rate_lambda, learning_rate_gamma, competition):\n",
    "\n",
    "    #lambda: Determines to what extent the new match results influence the team ratings (could be improved to include temporal difference between matches)\n",
    "    #learning_rate_lambda = 0.054\n",
    "\n",
    "    #psi: diminish the impact each additional goal difference error has on team ratings\n",
    "    diminishing_function_psi = lambda error: 3 * np.log10(1 + error)\n",
    "\n",
    "    #gamma: determines to what extent performances at the home grounds influence away team ratings and vice versa\n",
    "    #learning_rate_gamma = 0.79\n",
    "\n",
    "    #print(HomeTeam, \"-\", AwayTeam, FTHG, \":\", FTAG)\n",
    "\n",
    "\n",
    "    observed_goal_difference = FTHG - FTAG\n",
    "    #print(\"Observed Goal Difference:\", observed_goal_difference)\n",
    "\n",
    "    #Calculate expected goals for home team\n",
    "    #expected_goal_x = round((10 ** (abs(ratings[HomeTeam]['brH']) / 3)) - 1,5)\n",
    "    expected_goal_x_temp = abs(ratings[HomeTeam][competition]['brH']) / 3\n",
    "    expected_goal_x = np.sign(ratings[HomeTeam][competition]['brH']) * (np.power(10, expected_goal_x_temp) - 1)\n",
    "    #print(\"Expected Goals x:\", expected_goal_x)\n",
    "\n",
    "    # Calculate expected goals for away team\n",
    "    #expected_goal_y = round((10 ** (abs(ratings[AwayTeam]['brA']) / 3)) - 1,5)\n",
    "    expected_goal_y_temp = abs(ratings[AwayTeam][competition]['brA']) / 3\n",
    "    expected_goal_y = np.sign(ratings[AwayTeam][competition]['brA']) * (np.power(10, expected_goal_y_temp) - 1)\n",
    "    #print(\"Expected Goals y:\", expected_goal_y)\n",
    "\n",
    "    # Calculate expected goal difference based on ratings\n",
    "    expected_goal_difference = expected_goal_x - expected_goal_y\n",
    "    #print(\"Expected Goal Difference:\", expected_goal_difference)\n",
    "\n",
    "    # Calculate the error between observed and expected goal difference\n",
    "    error = abs(observed_goal_difference - expected_goal_difference)\n",
    "    #print(\"error:\", error)\n",
    "\n",
    "    psi_temp = diminishing_function_psi(error)\n",
    "\n",
    "    # Diminish the impact of the goal difference error for both teams x and y respectively\n",
    "    if (expected_goal_difference < observed_goal_difference):\n",
    "        diminishing_function_psi_x = psi_temp\n",
    "        diminishing_function_psi_y = -psi_temp\n",
    "    else:\n",
    "        diminishing_function_psi_x = -psi_temp\n",
    "        diminishing_function_psi_y = psi_temp\n",
    "    #print(\"Diminishing Function psi x:\", diminishing_function_psi_x)\n",
    "    #print(\"Diminishing Function psi y:\", diminishing_function_psi_y)\n",
    "\n",
    "    # Update the home team x background ratings\n",
    "    previous_home_rating_x = ratings[HomeTeam][competition]['brH']\n",
    "    previous_away_rating_x = ratings[HomeTeam][competition]['brA']\n",
    "    #print(\"Old brH x:\", previous_home_rating_x)\n",
    "    #print(\"Old brA x:\", previous_away_rating_x)\n",
    "\n",
    "    ratings[HomeTeam][competition]['brH'] = previous_home_rating_x + diminishing_function_psi_x * learning_rate_lambda\n",
    "    ratings[HomeTeam][competition]['brA'] = previous_away_rating_x + (ratings[HomeTeam][competition]['brH'] - previous_home_rating_x) * learning_rate_gamma\n",
    "    #print(\"New brH x:\", ratings[HomeTeam]['brH'])\n",
    "    #print(\"New brA x:\", ratings[HomeTeam]['brA'])\n",
    "\n",
    "    # Update the away team y background ratings\n",
    "    previous_home_rating_y = ratings[AwayTeam][competition]['brH']\n",
    "    previous_away_rating_y = ratings[AwayTeam][competition]['brA']\n",
    "    #print(\"Old brH y:\", previous_home_rating_y)\n",
    "    #print(\"Old brA y:\", previous_away_rating_y)\n",
    "\n",
    "    ratings[AwayTeam][competition]['brA'] = previous_away_rating_y + diminishing_function_psi_y * learning_rate_lambda\n",
    "    ratings[AwayTeam][competition]['brH'] = previous_home_rating_y + (ratings[AwayTeam][competition]['brA'] - previous_away_rating_y) * learning_rate_gamma\n",
    "    #print(\"New brH y:\", ratings[AwayTeam]['brH'])\n",
    "    #print(\"New brA y:\", ratings[AwayTeam]['brA'])\n",
    "\n",
    "    #print(\"Old overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"Old overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'])\n",
    "\n",
    "    # Update the continuous over/underperformances for the home team\n",
    "    if (observed_goal_difference > expected_goal_difference):\n",
    "        ratings[HomeTeam][competition]['continuous_overunderperformances'] = max(1, ratings[HomeTeam][competition]['continuous_overunderperformances'] + 1)\n",
    "        ratings[AwayTeam][competition]['continuous_overunderperformances'] = min(-1, ratings[AwayTeam][competition]['continuous_overunderperformances'] - 1)\n",
    "    elif (observed_goal_difference < expected_goal_difference):\n",
    "        ratings[HomeTeam][competition]['continuous_overunderperformances'] = min(-1, ratings[HomeTeam][competition]['continuous_overunderperformances'] - 1)\n",
    "        ratings[AwayTeam][competition]['continuous_overunderperformances'] = max(1, ratings[AwayTeam][competition]['continuous_overunderperformances'] + 1)\n",
    "    else:\n",
    "        ratings[HomeTeam][competition]['continuous_overunderperformances'] = 0\n",
    "        ratings[AwayTeam][competition]['continuous_overunderperformances'] = 0\n",
    "\n",
    "    #print(\"New overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"New overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'], end='\\n\\n')\n",
    "\n",
    "    return ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to update ratings based on results data\n",
    "def update_league_ratings_single_game(HomeLeague, AwayLeague, FTHG, FTAG, league_ratings, learning_rate_lambda, learning_rate_gamma):\n",
    "\n",
    "    #lambda: Determines to what extent the new match results influence the team ratings (could be improved to include temporal difference between matches)\n",
    "    #learning_rate_lambda = 0.054\n",
    "\n",
    "    #psi: diminish the impact each additional goal difference error has on team ratings\n",
    "    diminishing_function_psi = lambda error: 3 * np.log10(1 + error)\n",
    "\n",
    "    #gamma: determines to what extent performances at the home grounds influence away team ratings and vice versa\n",
    "    #learning_rate_gamma = 0.79\n",
    "\n",
    "    #print(HomeTeam, \"-\", AwayTeam, FTHG, \":\", FTAG)\n",
    "\n",
    "\n",
    "    observed_goal_difference = FTHG - FTAG\n",
    "    #print(\"Observed Goal Difference:\", observed_goal_difference)\n",
    "\n",
    "    #Calculate expected goals for home team\n",
    "    #expected_goal_x = round((10 ** (abs(ratings[HomeTeam]['brH']) / 3)) - 1,5)\n",
    "    expected_goal_x_temp = abs(league_ratings[HomeLeague]['brH']) / 3\n",
    "    expected_goal_x = np.sign(league_ratings[HomeLeague]['brH']) * (np.power(10, expected_goal_x_temp) - 1)\n",
    "    #print(\"Expected Goals x:\", expected_goal_x)\n",
    "\n",
    "    # Calculate expected goals for away team\n",
    "    #expected_goal_y = round((10 ** (abs(ratings[AwayTeam]['brA']) / 3)) - 1,5)\n",
    "    expected_goal_y_temp = abs(league_ratings[AwayLeague]['brA']) / 3\n",
    "    expected_goal_y = np.sign(league_ratings[AwayLeague]['brA']) * (np.power(10, expected_goal_y_temp) - 1)\n",
    "    #print(\"Expected Goals y:\", expected_goal_y)\n",
    "\n",
    "    # Calculate expected goal difference based on ratings\n",
    "    expected_goal_difference = expected_goal_x - expected_goal_y\n",
    "    #print(\"Expected Goal Difference:\", expected_goal_difference)\n",
    "\n",
    "    # Calculate the error between observed and expected goal difference\n",
    "    error = abs(observed_goal_difference - expected_goal_difference)\n",
    "    #print(\"error:\", error)\n",
    "\n",
    "    psi_temp = diminishing_function_psi(error)\n",
    "\n",
    "    # Diminish the impact of the goal difference error for both teams x and y respectively\n",
    "    if (expected_goal_difference < observed_goal_difference):\n",
    "        diminishing_function_psi_x = psi_temp\n",
    "        diminishing_function_psi_y = -psi_temp\n",
    "    else:\n",
    "        diminishing_function_psi_x = -psi_temp\n",
    "        diminishing_function_psi_y = psi_temp\n",
    "    #print(\"Diminishing Function psi x:\", diminishing_function_psi_x)\n",
    "    #print(\"Diminishing Function psi y:\", diminishing_function_psi_y)\n",
    "\n",
    "    # Update the home team x background ratings\n",
    "    previous_home_rating_x = league_ratings[HomeLeague]['brH']\n",
    "    previous_away_rating_x = league_ratings[HomeLeague]['brA']\n",
    "    #print(\"Old brH x:\", previous_home_rating_x)\n",
    "    #print(\"Old brA x:\", previous_away_rating_x)\n",
    "\n",
    "    league_ratings[HomeLeague]['brH'] = previous_home_rating_x + diminishing_function_psi_x * learning_rate_lambda\n",
    "    league_ratings[HomeLeague]['brA'] = previous_away_rating_x + (league_ratings[HomeLeague]['brH'] - previous_home_rating_x) * learning_rate_gamma\n",
    "    #print(\"New brH x:\", ratings[HomeTeam]['brH'])\n",
    "    #print(\"New brA x:\", ratings[HomeTeam]['brA'])\n",
    "\n",
    "    # Update the away team y background ratings\n",
    "    previous_home_rating_y = league_ratings[AwayLeague]['brH']\n",
    "    previous_away_rating_y = league_ratings[AwayLeague]['brA']\n",
    "    #print(\"Old brH y:\", previous_home_rating_y)\n",
    "    #print(\"Old brA y:\", previous_away_rating_y)\n",
    "\n",
    "    league_ratings[AwayLeague]['brA'] = previous_away_rating_y + diminishing_function_psi_y * learning_rate_lambda\n",
    "    league_ratings[AwayLeague]['brH'] = previous_home_rating_y + (league_ratings[AwayLeague]['brA'] - previous_away_rating_y) * learning_rate_gamma\n",
    "    #print(\"New brH y:\", ratings[AwayTeam]['brH'])\n",
    "    #print(\"New brA y:\", ratings[AwayTeam]['brA'])\n",
    "\n",
    "    #print(\"Old overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"Old overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'])\n",
    "\n",
    "    # Update the continuous over/underperformances for the home team\n",
    "    if (observed_goal_difference > expected_goal_difference):\n",
    "        league_ratings[HomeLeague]['continuous_overunderperformances'] = max(1, league_ratings[HomeLeague]['continuous_overunderperformances'] + 1)\n",
    "        league_ratings[AwayLeague]['continuous_overunderperformances'] = min(-1, league_ratings[AwayLeague]['continuous_overunderperformances'] - 1)\n",
    "    elif (observed_goal_difference < expected_goal_difference):\n",
    "        league_ratings[HomeLeague]['continuous_overunderperformances'] = min(-1, league_ratings[HomeLeague]['continuous_overunderperformances'] - 1)\n",
    "        league_ratings[AwayLeague]['continuous_overunderperformances'] = max(1, league_ratings[AwayLeague]['continuous_overunderperformances'] + 1)\n",
    "    else:\n",
    "        league_ratings[HomeLeague]['continuous_overunderperformances'] = 0\n",
    "        league_ratings[AwayLeague]['continuous_overunderperformances'] = 0\n",
    "\n",
    "    #print(\"New overunderperformance x:\", ratings[HomeTeam]['continuous_overunderperformances'])\n",
    "    #print(\"New overunderperformance y:\", ratings[AwayTeam]['continuous_overunderperformances'], end='\\n\\n')\n",
    "\n",
    "    return league_ratings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_provisional_ratings(ratings, team, competition):\n",
    "\n",
    "    #phi: Represents the number of continuous performances, above or below expectations, which do not trigger the form factor\n",
    "    form_threshold_phi = 1\n",
    "\n",
    "    #mu: represents the rating difference used to establish provisional ratings from background ratings\n",
    "    rating_impact_mu = 0.01\n",
    "\n",
    "    #delta: the level by which rating impact μ diminishes with each additional continuous over/under-performance\n",
    "    diminishing_factor_delta = 2.5\n",
    "\n",
    "    brH = ratings[team][competition]['brH']  # Background rating home\n",
    "    brA = ratings[team][competition]['brA']  # Background rating away\n",
    "    prH = brH\n",
    "    prA = brA\n",
    "\n",
    "    return prH, prA\n",
    "\n",
    "    if abs(ratings[team][competition]['continuous_overunderperformances']) < 2:\n",
    "        return prH, prA\n",
    "\n",
    "    # Calculate performance factor for home team x\n",
    "    a = abs(ratings[team][competition]['continuous_overunderperformances']) - form_threshold_phi\n",
    "    b = a ** diminishing_factor_delta\n",
    "    form_factor_home = a / b\n",
    "\n",
    "    # Calculate provisional rating of the team\n",
    "    if (ratings[team][competition]['continuous_overunderperformances'] > form_threshold_phi):\n",
    "        prH = brH + rating_impact_mu * form_factor_home\n",
    "        prA = brA + rating_impact_mu * form_factor_home\n",
    "    if (ratings[team][competition]['continuous_overunderperformances'] < -form_threshold_phi):\n",
    "        prH = brH - rating_impact_mu * form_factor_home\n",
    "        prA = brA - rating_impact_mu * form_factor_home\n",
    "\n",
    "    #return prH, prA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_probabilities(features):\n",
    "    # Load the model and label encoder\n",
    "    model = joblib.load('../Models/model.pkl')\n",
    "\n",
    "    # Now you can predict probabilities for a new game:\n",
    "    new_game_rating_difference = np.array([features])\n",
    "    probabilities = model.predict_proba(new_game_rating_difference)\n",
    "    return probabilities[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to calculate the rating difference between two teams\n",
    "def calculate_rating_difference(HomeTeam, AwayTeam, competition, ratings):\n",
    "\n",
    "    # Calculate home team rating\n",
    "    home_rating_x = ratings[HomeTeam][competition]['brH']\n",
    "    if (abs(ratings[HomeTeam][competition]['continuous_overunderperformances']) > 1):\n",
    "        provisional_ratings_x = calculate_provisional_ratings(ratings, HomeTeam, competition)\n",
    "        home_rating_x = provisional_ratings_x[0]\n",
    "\n",
    "    # Calculate away team rating\n",
    "    away_rating_y = ratings[AwayTeam][competition]['brA']\n",
    "    if (abs(ratings[AwayTeam][competition]['continuous_overunderperformances']) > 1):\n",
    "        provisional_ratings_y = calculate_provisional_ratings(ratings, AwayTeam, competition)\n",
    "        away_rating_y = provisional_ratings_y[1]\n",
    "\n",
    "    # Calculate rating difference\n",
    "    rating_difference = home_rating_x - away_rating_y\n",
    "\n",
    "    return rating_difference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_outcomes(df_fixtures, ratings, learning_rate_lambda, learning_rate_gamma):\n",
    "\n",
    "    all_rps = []\n",
    "\n",
    "    for index, row in df_fixtures.iterrows():\n",
    "        HomeTeam = row['HomeTeam']\n",
    "        AwayTeam = row['AwayTeam']\n",
    "        competition = row['Div']\n",
    "\n",
    "        # Initialize league table for the competition if it doesn't exist\n",
    "        if competition not in league_tables:\n",
    "            league_tables[competition] = pd.DataFrame(columns=['team', 'games_played', 'points'])\n",
    "\n",
    "\n",
    "        rating_difference = calculate_rating_difference(HomeTeam, AwayTeam, competition, ratings)\n",
    "\n",
    "        \"\"\"\n",
    "        prH_x = calculate_provisional_ratings(ratings, HomeTeam, competition)[0]\n",
    "        prA_x = calculate_provisional_ratings(ratings, AwayTeam, competition)[1]\n",
    "        prH_y = calculate_provisional_ratings(ratings, HomeTeam, competition)[0]\n",
    "        prA_y = calculate_provisional_ratings(ratings, AwayTeam, competition)[1]\n",
    "        \"\"\"\n",
    "\n",
    "        #features = [prH_x, prA_x, prH_y, prA_y]\n",
    "        features = [rating_difference]\n",
    "\n",
    "        away_win_prob, draw_prob, home_win_prob = calculate_probabilities(features)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        FTHG = int(row['FTHG'])\n",
    "        FTAG = int(row['FTAG'])\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"{HomeTeam} - {AwayTeam} {FTHG}:{FTAG}\")\n",
    "        print(f\"Home Win Prob: {home_win_prob}\")\n",
    "        print(f\"Draw Prob: {draw_prob}\")\n",
    "        print(f\"Away Win Prob: {away_win_prob}\", end='\\n\\n')\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Call Ranked Probability Score function\n",
    "        probs = [home_win_prob, draw_prob, away_win_prob]\n",
    "        if row[\"FTR\"] == \"H\":\n",
    "            outcome = [1, 0, 0]\n",
    "        elif row[\"FTR\"] == \"D\":\n",
    "            outcome = [0, 1, 0]\n",
    "        else:\n",
    "            outcome = [0, 0, 1]\n",
    "\n",
    "        rps_score = rps(probs, outcome)\n",
    "        #print(\"RPS Score:\", rps_score, end='\\n\\n')\n",
    "        all_rps.append(rps_score)\n",
    "\n",
    "        # Update league table\n",
    "        league_tables[competition] = update_league_table(league_tables[competition], HomeTeam, AwayTeam, home_win_prob, draw_prob, away_win_prob)\n",
    "\n",
    "        # Update ratings\n",
    "        ratings = update_ratings_single_game(HomeTeam, AwayTeam, row['FTHG'], row['FTAG'], ratings, learning_rate_lambda, learning_rate_gamma, competition)\n",
    "\n",
    "    print(f\"Average RPS Score for {competition}:\", np.mean(all_rps), '\\n')\n",
    "\n",
    "    # Sort all league tables\n",
    "    for competition, table in league_tables.items():\n",
    "        assert isinstance(table, pd.DataFrame), f\"Unexpected object: {type(table)} for competition: {competition}\"\n",
    "        table = table.sort_values(['points', 'games_played'], ascending=False)\n",
    "        table = table.reset_index(drop=True)\n",
    "        league_tables[competition] = table\n",
    "\n",
    "    return all_rps, league_tables\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def update_league_table(league_table, HomeTeam, AwayTeam, home_win_prob, draw_prob, away_win_prob):\n",
    "\n",
    "    # Calculate points based on probabilities\n",
    "    home_points = home_win_prob * 3 + draw_prob * 1\n",
    "    away_points = away_win_prob * 3 + draw_prob * 1\n",
    "\n",
    "    # Home team update\n",
    "    if HomeTeam in league_table['team'].values:\n",
    "        league_table.loc[league_table['team'] == HomeTeam, 'games_played'] += 1\n",
    "        league_table.loc[league_table['team'] == HomeTeam, 'points'] += home_points\n",
    "    else:\n",
    "        df_home = pd.DataFrame({'team': [HomeTeam], 'games_played': [1], 'points': [home_points]})\n",
    "        league_table = pd.concat([league_table, df_home], ignore_index=True)\n",
    "\n",
    "    # Away team update\n",
    "    if AwayTeam in league_table['team'].values:\n",
    "        league_table.loc[league_table['team'] == AwayTeam, 'games_played'] += 1\n",
    "        league_table.loc[league_table['team'] == AwayTeam, 'points'] += away_points\n",
    "    else:\n",
    "        df_away = pd.DataFrame({'team': [AwayTeam], 'games_played': [1], 'points': [away_points]})\n",
    "        league_table = pd.concat([league_table, df_away], ignore_index=True)\n",
    "\n",
    "    return league_table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rps(probs, outcome):\n",
    "    cum_probs = np.cumsum(probs)\n",
    "    cum_outcomes = np.cumsum(outcome)\n",
    "\n",
    "    sum_rps = 0\n",
    "    for i in range(len(outcome)):\n",
    "        sum_rps+= (cum_probs[i] - cum_outcomes[i])**2\n",
    "\n",
    "    return sum_rps/(len(outcome)-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def train_model(df_train):\n",
    "\n",
    "    # Create Logistic Regression model\n",
    "    #model = LogisticRegression(solver=\"saga\", penalty=\"l2\")  # 'ovr' stands for One-Vs-Rest\n",
    "    model = MLPClassifier(solver='lbfgs', alpha=1e-2, hidden_layer_sizes=(5, 2), random_state=23, max_iter=1000)\n",
    "\n",
    "    # Reshape rating_difference to 2D array for model fitting\n",
    "    #X = df_train[['prH_x', 'prA_x', \"prH_y\", \"prA_y\"]].values\n",
    "    X = df_train[\"rating_difference\"].values.reshape(-1, 1)\n",
    "    y = df_train['FTR']\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.00001, random_state=42)\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and label encoder here\n",
    "    joblib.dump(model, '../Models/model.pkl')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score = model.score(X_test, y_test)\n",
    "    #print(f'Model accuracy: {score*100:.2f}%')\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Main Function\n",
    "\n",
    "# Load the results data file for seasons 2010-2011 to 2021-2022\n",
    "df_results = pd.read_csv('../data/season_2010-2022_sorted_compressed_top.csv')\n",
    "\n",
    "# Load the fixtures data file for the season 2022-2023\n",
    "df_fixtures = pd.read_csv('../data/season_2022-2023_sorted_top.csv')\n",
    "\n",
    "# Initialize ratings based on the results data\n",
    "ratings, league_ratings = initialize_ratings(df_results, df_fixtures)\n",
    "\n",
    "learning_rate_lambda = 0.04\n",
    "learning_rate_gamma = 1.0\n",
    "\n",
    "# Update ratings based on the results data here\n",
    "ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, learning_rate_lambda, learning_rate_gamma)\n",
    "#model.C_\n",
    "\n",
    "df_international = pd.read_csv('../data/season_2016-2022_INT.csv')\n",
    "team_to_league, rest_teams = create_team_to_league_mapping(df_results, df_fixtures, df_international)\n",
    "print(team_to_league, end='\\n\\n')\n",
    "\n",
    "league_ratings = update_league_ratings_multiple_games(df_international, league_ratings, team_to_league, learning_rate_lambda, learning_rate_gamma)\n",
    "for league, values in league_ratings.items():\n",
    "    print(f\"League: {league}, Rating: {values['brH']}\")\n",
    "print('REST:', rest_teams, end='\\n\\n')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.annotate(\"Background Rating over time\", (0.5, 1.05), xycoords='axes fraction', ha='center', va='center', size=16)\n",
    "df_ratings = pd.DataFrame(games_with_ratings)\n",
    "teams = [\"Arsenal\", \"Man City\", \"Man United\", \"Chelsea\", \"Tottenham\", \"Liverpool\", \"Everton\", \"Leicester\", \"West Ham\", \"Southampton\"]\n",
    "#for team in df_ratings[\"team\"].unique()[:10]:\n",
    "for team in teams:\n",
    "    per_team = df_ratings.loc[df_ratings[\"team\"] == team]\n",
    "    plt.plot((per_team[\"home_rating\"] + per_team[\"away_rating\"]) / 2, label=team)\n",
    "plt.legend()\n",
    "plt.savefig(\"../images/ratings_over_time232.png\", dpi=300)\n",
    "\n",
    "df_train = pd.DataFrame(training_games)\n",
    "\n",
    "df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "\n",
    "model = train_model(df_train)\n",
    "\n",
    "# Initialize an empty league tables dictionary and rps list\n",
    "league_tables = {}\n",
    "all_rps = []\n",
    "\n",
    "# Predict the probabilities of home win, draw and away win for the fixtures data\n",
    "for competition in df_fixtures['Div'].unique():\n",
    "    competition_fixtures = df_fixtures[df_fixtures['Div'] == competition]\n",
    "    competition_rps, league_tables = predict_outcomes(competition_fixtures, ratings, learning_rate_lambda, learning_rate_gamma)\n",
    "    all_rps.extend(competition_rps)  # extend the list with rps scores from the current competition\n",
    "\n",
    "# Now you can calculate the mean RPS across all competitions\n",
    "mean_rps = np.mean(all_rps)\n",
    "print(\"Average RPS Score across all competitions:\", mean_rps)\n",
    "\n",
    "# Save league tables to file\n",
    "for competition, league_table in league_tables.items():\n",
    "    league_table.to_csv(f\"../league_tables/{competition}_league_table.csv\", index=False)\n",
    "\n",
    "\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print league tables\n",
    "for competition, league_table in league_tables.items():\n",
    "    print(f\"League table for {competition}:\")\n",
    "    league_table_df = league_table.copy()  # creating a copy to avoid modifying the original data\n",
    "    league_table_df.index = league_table_df.index + 1\n",
    "    print(league_table_df)\n",
    "    league_table_df.index = league_table_df.index - 1\n",
    "\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot RPS distribution\n",
    "plt.annotate(\"RPS Distribution\", (0.5, 0.9), xycoords='axes fraction', ha='center', va='center', size=16)\n",
    "plt.hist(all_rps, bins=25)\n",
    "plt.savefig(\"../images/rps_distribution232.png\", dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for team, team_ratings in ratings.items():\n",
    "    print(f\"Team: {team}\")\n",
    "    print(f\"Background Rating Home: {team_ratings['brH']}\")\n",
    "    print(f\"Background Rating Away: {team_ratings['brA']}\")\n",
    "    print(f\"Continuous Over/Underperformances: {team_ratings['continuous_overunderperformances']}\")\n",
    "    print()\n",
    "\"\"\"\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define a parameter grid with the ranges for your parameters\n",
    "param_grid = {\n",
    "    'learning_rate_lambda': np.arange(0.02, 0.051, 0.005),\n",
    "    'learning_rate_gamma': np.arange(0.9, 1.01, 0.05)\n",
    "}\n",
    "\n",
    "# Create a ParameterGrid object from the dictionary\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Initialize the best_score variable and best_params dictionary\n",
    "best_score = float('inf')  # assuming lower scores are better; use -float('inf') if higher scores are better\n",
    "best_params = {}\n",
    "\n",
    "# Create an empty list to store the results\n",
    "gs_results = []\n",
    "\n",
    "# Loop over the parameter combinations\n",
    "for params in tqdm.tqdm(grid):\n",
    "    ratings = initialize_ratings(df_results, df_fixtures)\n",
    "\n",
    "    # Update your learning rates\n",
    "    learning_rate_lambda = params['learning_rate_lambda']\n",
    "    learning_rate_gamma = params['learning_rate_gamma']\n",
    "\n",
    "    # Re-train model with the new parameters\n",
    "    ratings, games_with_ratings, training_games = update_ratings_multiple_games(df_results, ratings, learning_rate_lambda, learning_rate_gamma)\n",
    "\n",
    "    df_train = pd.DataFrame(training_games)\n",
    "    df_train.to_csv(\"../data/train232.csv\", index=False)\n",
    "    model = train_model(df_train)\n",
    "\n",
    "    all_rps, league_tables = predict_outcomes(df_fixtures, ratings, learning_rate_lambda, learning_rate_gamma)\n",
    "    score = np.mean(all_rps)\n",
    "\n",
    "    # If the current score is better than the best_score, update best_score and best_params\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "    # Store the current score and parameters\n",
    "    gs_results.append({\n",
    "        'learning_rate_lambda': learning_rate_lambda,\n",
    "        'learning_rate_gamma': learning_rate_gamma,\n",
    "        'score': score,\n",
    "    })\n",
    "\n",
    "print(f'Best score: {best_score}')\n",
    "print(f'Best params: {best_params}')\n",
    "\n",
    "# Convert the gs_results to a DataFrame and plot them\n",
    "df_gs_results = pd.DataFrame(gs_results)\n",
    "\n",
    "# Define grid of x, y values\n",
    "lambda_range = np.linspace(df_gs_results['learning_rate_lambda'].min(), df_gs_results['learning_rate_lambda'].max(), num=50)\n",
    "gamma_range = np.linspace(df_gs_results['learning_rate_gamma'].min(), df_gs_results['learning_rate_gamma'].max(), num=50)\n",
    "lambda_grid, gamma_grid = np.meshgrid(lambda_range, gamma_range)\n",
    "\n",
    "# Interpolate z values for this grid\n",
    "rps_grid = griddata((df_gs_results['learning_rate_lambda'], df_gs_results['learning_rate_gamma']), df_gs_results['score'], (lambda_grid, gamma_grid), method='cubic')\n",
    "\n",
    "# Create 3D surface plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(lambda_grid, gamma_grid, rps_grid, cmap='RdYlGn_r', edgecolor='none')\n",
    "ax.set_xlabel('Lambda')\n",
    "ax.set_ylabel('Gamma')\n",
    "ax.set_zlabel('RPS Score', fontsize=10, labelpad=5)\n",
    "ax.invert_zaxis()  # To make lower scores appear higher\n",
    "#fig.colorbar(surf)\n",
    "plt.savefig(\"../images/3d_plot_gs232.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create 2D plot with colormap\n",
    "plt.figure(figsize=(10, 10))  # Adjust figsize to your preference to make the plot square\n",
    "plt.title('Grid Search Scores')\n",
    "\n",
    "cmap_reversed = plt.cm.get_cmap('RdYlGn_r')  # Reversed Red-Yellow-Green colormap\n",
    "\n",
    "# Here we store the image object returned by imshow\n",
    "im = plt.imshow(rps_grid, interpolation='nearest', cmap=cmap_reversed,\n",
    "           extent=(param_grid['learning_rate_lambda'].min(), param_grid['learning_rate_lambda'].max(), param_grid['learning_rate_gamma'].min(), param_grid['learning_rate_gamma'].max()), origin='lower')\n",
    "\n",
    "# We use the stored image object for the colorbar\n",
    "plt.colorbar(im, cmap=cmap_reversed)\n",
    "\n",
    "plt.axis('square')  # This will enforce a square aspect ratio\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Gamma\")\n",
    "plt.savefig(\"../images/2d_plot_heat_gs232.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Convert grid search results into a pivot table for plotting\n",
    "pivot_table = df_gs_results.pivot('learning_rate_lambda', 'learning_rate_gamma', 'score')\n",
    "\n",
    "# Create contour plot\n",
    "plt.figure(figsize=(10,7))\n",
    "contour_plot = plt.contourf(pivot_table.columns, pivot_table.index, pivot_table.values, cmap='RdYlGn_r', levels=100)\n",
    "plt.title('Grid Search RPS Scores')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Gamma')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(contour_plot)\n",
    "cbar.ax.set_ylabel('RPS Score')\n",
    "\n",
    "plt.savefig(\"../images/2d_plot_contour_gs232.png\", dpi=300)\n",
    "plt.show()\n",
    "\"\"\"\n",
    ";"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
